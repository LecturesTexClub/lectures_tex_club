\subsubsection{Построение доверительных интервалов}

\begin{proposition}
	Если имеется асимптотически нормальная оценка $\hat{\theta}_n(X)$ с непрерывным асимптотическим среднеквадратичным отклонением $\sigma(\theta) > 0$, то мы можем построить асимптотический доверительный интервал уровня доверия $\gamma$ для $\theta$ следующего вида:
	\[
		\ps{\hat{\theta}_n(X) - u_{\frac{1 + \gamma}{2}} \cdot \frac{\sigma(\hat{\theta}_n)}{\sqrt{n}}, \hat{\theta}_n(X) + u_{\frac{1 + \gamma}{2}} \cdot \frac{\sigma(\hat{\theta}_n)}{\sqrt{n}}}
	\]
	где $\sigma(\hat{\theta}_n)$ --- среднеквадратичное отклонение оценки $\hat{\theta}_n(X)$, $u_p$ --- $p$-квантиль распределения $N(0, 1)$.
\end{proposition}

\begin{proof}
	Действительно, воспользуемся определением асимптотической нормальности:
	\[
		\forall \theta \in \Theta\ \ \sqrt{n}(\hat{\theta}_n(X) - \theta) \xrightarrow[n \to \infty]{d_\theta} N(0, \sigma^2(\theta))
	\]
	Поделим на $\sigma(\theta)$, чтобы перейти к $N(0, 1)$ в правой части, однако это создаст проблемы слева, ибо появится лишняя зависимость от $\theta$:
	\[
		\forall \theta \in \Theta\ \ \frac{\sqrt{n}(\hat{\theta}_n(X) - \theta)}{\sigma(\theta)} \xrightarrow[n \to \infty]{d_\theta} N(0, 1)
	\]
	Эту проблему можно решить при помощи леммы Слуцкого. Действительно, в силу асимптотической нормальности, $\hat{\theta}_n(X) \to^{P_\theta} \theta$, причём $\sigma(\theta)$ непрерывна по условию. Стало быть, есть сходимость $\sigma(\hat{\theta}_n(X)) \to^{P_\theta} \sigma(\theta)$. При помощи упомянутой леммы можем собрать это в следующий факт:
	\[
		\forall \theta \in \Theta\ \ \frac{\sqrt{n}(\hat{\theta}_n(X) - \theta)}{\sigma(\theta)} \cdot \frac{\sigma(\theta)}{\sigma(\hat{\theta}_n)} \xrightarrow[n \to \infty]{d_\theta} N(0, 1) \cdot 1 = N(0, 1)
	\]
	Далее мы классически рассматриваем вероятность попадания между $u_{\frac{1 - \gamma}{2}}$ и $u_{\frac{1 + \gamma}{2}}$, которая будет сходиться к $\gamma$. Её несложно свернуть в следующую форму:
	\[
		\forall \theta \in \Theta\ \ P_\theta\ps{\sqrt{n}\md{\frac{\hat{\theta}_n(X) - \theta}{\sigma(\hat{\theta}_n)}} < u_{\frac{1 + \gamma}{2}}} \xrightarrow[n \to \infty]{} \gamma
	\]
	Таким образом, мы нашли нужный асимптотический доверительный интервал.
\end{proof}

\subsection{Метод максимального правдоподобия}

\begin{note}
	Далее мы живём в вероятностно-статистическом пространстве $(\cX, \B(\cX), \cP)$, $\cP = \{P_\theta, \theta \in \Theta\}$.
\end{note}

\begin{definition}
	Пусть $X$ --- наблюдение с неизвестным распределением $P_\theta \in \cP$, причём $\cP$ доминируется относительно меры $\mu$. \textit{Функцией правдоподобия} называется функция $f_\theta(x) = p_\theta(x)$, где $p_\theta$ --- плотность $P_\theta$ по мере $\mu$.
\end{definition}

\begin{anote}
	В физическом смысле, функция правдоподобия говорит статисту, насколько вероятен тот или иной исход.
\end{anote}

\begin{example}
	Пусть $X = (X_1, \ldots, X_n)$ --- выборка с плотностью $p_\theta(x)$. Тогда функция правдоподобия является плотностью $X$ как наблюдения:
	\[
		f_\theta(x) = p_\theta(x) = \prod_{i = 1}^n p_\theta(x_i)
	\]
\end{example}

\begin{definition}
	Пусть $X$ --- наблюдение с функцией правдоподобия $f_\theta$. \textit{Оценкой параметра $\theta$ по методу максимального правдоподобия (ОМП)} называется такая статистика $\hat{\theta}(X)$, что верно равенство:
	\[
		\hat{\theta}(X) = \arg\max_{\theta \in \Theta} f_\theta(X)
	\]
\end{definition}

\begin{anote}
	То есть из всех возможных параметров ОМП выбирает тот, при котором заданная выборка наиболее вероятна.
\end{anote}

\begin{example}
	Рассмотрим дискретную модель трёх бросков монетки с вероятностью $\theta$ получения орла и исход $X = (1, 1, 0)$. Тогда, для $\theta_1 = \frac{1}{9}$ мы имеем значение функции правдоподобия $\frac{8}{9^3}$, а для $\theta_2 = \frac{7}{8}$ это будет $\frac{7^2}{8^3}$ и это больше предыдущей вероятности. В связи с этим мы верим, что вторая монетка должна лучше предсказывать реальность, нежели первая.
\end{example}

\begin{example}
	Найдём явно оценку ОМП в базовом случае $X_i \sim U[0; \theta]$. Тогда функция правдоподобия имеет вид:
	\[
		f_\theta(X) = \frac{1}{\theta^n} \prod_{i = 1}^n \chi\{0 \le X_i \le \theta\} = \frac{\chi\{0 \le X_{(1)} \le X_{(n)} \le \theta\}}{\theta^n}
	\]
	Так как мы считаем, что реализация выборки $X$ фиксирована при выборе $\theta$, то оценка должна быть очевидна: $\hat{\theta}(X) = X_{(n)}$. \textcolor{red}{Исправить, тут не вероятность написана, а что-то другое}
\end{example}

\begin{definition}
	Функция $L_\theta(x) = \ln f_\theta(x)$ называется \textit{логарифом функции правдоподобия}.
\end{definition}

\begin{note}
	Далее мы расширяем и нумеруем \textit{условия регулярности}:
	\begin{enumerate}
		\item[0.] $\cP$ - доминируемое семейство относительно меры $\mu$.
		
		\item Множество носителей $A = \{x \in \cX \colon p_\theta(x) > 0\}$ не зависит от $\theta$
		
		\item Наблюдение $X$ есть выборка из неизвестного распределения $P_\theta$
		
		\item $\Theta \subseteq \R$ --- открытый интервал (возможно бесконечный)
		
		\item Функция $p_\theta(x)$ непрерывно дифференцируема по $\theta$ при всех $x \in A$
		
		\item Функция $p_\theta(x)$ трижды непрерывно дифференцируема по $\theta$ при всех $x \in A$
		
		\item Интеграл $\int_A p_\theta(x)d\mu(x)$ трижды дифференцируем по $\theta$ под знаком интеграла
		
		\item Имеет место конечность информации Фишера для одного наблюдения из выборки:
		\[
			\E_\theta\ps{\pd{}{\theta} \ln p_\theta(X_1)}^2 = i(\theta) \in (0; +\infty)
		\]
		
		\item Существует равномерная интегрируемая оценка сверху в некотором интервале вокруг любого параметра $\theta_0 \in \Theta$:
		\[
			\forall \theta_0 \in \Theta\ \exists c > 0, H(x) \such \E_\theta H(X) < \infty \wedge \forall \theta \in (\theta_0 - c; \theta_0 + c),\ x \in A\ \ \md{\pd{^3}{\theta^3} \ln p_\theta(x)} < H(x)
		\]
	\end{enumerate}
\end{note}

\begin{theorem} (Экстремальное свойство правдоподобия)
	Пусть выполнены условия регулярности 0-2. Тогда
	\[
		\forall \theta_0, \theta \in \Theta\ \ (\theta_0 \neq \theta) \Ra \lim_{n \to \infty} P_{\theta_0}(f_{\theta_0}(X_1, \ldots, X_n) > f_\theta(X_1, \ldots, X_n)) = 1
	\]
\end{theorem}

\begin{proof}
	Рассмотрим $x_i \in A$. Тогда есть цепочка эквивалентностей:
	\[
		f_{\theta_0}(x_1, \ldots, x_n) > f_\theta(x_1, \ldots, x_n) \Lra \frac{1}{n}\ln\frac{f_\theta(x_1, \ldots, x_n)}{f_{\theta_0}(x_1, \ldots, x_n)} < 0 \Lra \frac{1}{n}\sum_{i = 1}^n \ln\frac{f_\theta(x_i)}{f_{\theta_0}(x_i)} < 0
	\]
	Получили выражение, которое является средним арифметическим от $\ln\frac{f_\theta(x_i)}{f_{\theta_0}(x_i)}$. По УЗБЧ, если мы заменим $x_i$ на $X_i \sim P_{\theta_0}$, будет сходимость $P_{\theta_0}$-почти наверное к матожиданию $\E_{\theta_0} \ln\frac{f_\theta(X_1)}{f_{\theta_0}(X_1)}$. Если оно меньше нуля, то требуемое доказано:
	\begin{multline*}
		\E_{\theta_0} \ln\frac{p_\theta(X_1)}{p_{\theta_0}(X_1)} = \int_A \ln\ps{\frac{p_\theta(x)}{p_{\theta_0}(x)}}p_{\theta_0}(x)d\mu(x) = \int_A \ln\ps{1 + \frac{p_\theta(x)}{p_{\theta_0}(x)} - 1}p_{\theta_0}(x)d\mu(x) \le
		\\
		\int_A \ps{\frac{p_\theta(x)}{p_{\theta_0}(x)} - 1}p_{\theta_0}(x)d\mu(x) = \int_A p_\theta(x)d\mu(x) - \int_A p_{\theta_0}(x)d\mu(x) = 1 - 1 = 0
	\end{multline*}
	Последнее равенство опирается на то, что $A$ --- это носитель положительной вероятности. Сейчас мы доказали нестрогое неравенство, а надо строгое. Если выполнено равенство, то в том числе
	\[
		\int_A \ln\ps{1 + \frac{p_\theta(x)}{p_{\theta_0}(x)} - 1}p_{\theta_0}(x)d\mu(x) = 0 = \int_A \ps{\frac{p_\theta(x)}{p_{\theta_0}(x)} - 1}p_{\theta_0}(x)d\mu(x)
	\]
	Так как $\ln(1 + p_\theta(x) / p_{\theta_0}(x) - 1) \le p_\theta(x) / p_{\theta_0}(x) - 1$, то такое возможно тогда и только тогда, когда эти функции равны почти-наверное на $A$. Стало быть, $\mu\{x \in A \colon p_\theta(x) \neq p_{\theta_0}(x)\} = 0$, а это противоречит условию регулярности 0. Значит неравенство строгое, что и требовалось.
\end{proof}

\begin{corollary}
	Если $\Theta$ --- конечное множество, то ОМП существует и единственна с вероятностью, стремящейся к единице (то есть, есть множество, на котором ОМП принимает одно и то же истинное значение, и вероятность этого множества стремится к 1) и состоятельна.
\end{corollary}

\begin{proof}
	ОМП имеет вид $\wh{\theta}(X) = \arg\max_{l \in \{1, \ldots, L\}} f_{\theta_l}(X)$. Если есть несколько кандидатов в максимум, то выбираем то $\theta_l$, чей номер минимален. Существование в таком виде тривиально, но теперь надо установить измеримость оценки (что она является случайной величиной). Введём событие $C_{i < j} = \{x \colon f_{\theta_i}(x) < f_{\theta_j}(x)\}$, аналогично $C_{i \le j}$. Тогда мы можем описать прообраз оценки следующим образом:
	\[
		\{x \colon \wh{\theta}(x) = \theta_i\} = \ps{\bigcap_{l < i} C_{l < i}} \cap \ps{\bigcap_{l > i} C_{l \le i}}
	\]
	Так как $f_{\theta_i}$ есть фактически плотность меры $P_{\theta_i}$, то это измеримая функция. Стало быть, каждое множество $C_{l < i}$, $C_{l \le i}$ в конечном пересечении измеримо, а значит и пересечение тоже измеримо. Причём, если $X_k \sim P_{\theta_i}$, то работает доказанная теорема и вероятность такого множества стремится к единице (этим установлена единственность и одновременно состоятельность).
\end{proof}

\begin{definition}
	\textit{Уравнением правдоподобия} называется одно из двух эквивалентных уравнений:
	\[
		\pd{\ln f_\theta}{\theta} = 0 \Lra \pd{f_\theta}{\theta} = 0
	\]
\end{definition}

\begin{theorem} (Аналог состоятельности ОМП)
	Пусть выполнены условия регулярности $0$-$4$ и элементы выборки $X_1, \ldots, X_n \sim P_{\theta_0}$. Тогда, существует отображение \\ $\wh{\theta}_n(X_1, \ldots, X_n, \theta_0)$ со значениями в $\Theta$, для которого есть свойства:
	\begin{itemize}
		\item $\lim_{n \to \infty} P_{\theta_0}^*\{\wh{\theta}_n \text{ --- не решение уравнения правдоподобия}\} = 0$
		
		\item $\forall \eps > 0\ \ \lim_{n \to \infty} P_{\theta_0}^*\{|\wh{\theta}_n - \theta_0| > \eps\} = 0$
	\end{itemize}
	где $P_{\theta_0}^*$ --- внешняя мера $P_{\theta_0}$.
\end{theorem}

\begin{note}
	Неформально, с ростом размера выборки $\wh{\theta}_n$ мы, во-первых, получаем через $\wh{\theta}_n$ корень уравнения правдоподобия, а во-вторых, он будет близок к $\theta_0$.
\end{note}

\begin{proof}
	Пусть $x_1, \ldots, x_n \in A$ --- реализация выборки. Определим $\wh{\theta}_n$ следующим образом:
	\begin{itemize}
		\item Если у уравнения правдоподобия $\pd{\ln f_\theta}{\theta}(x_1, \ldots, x_n, \theta) = 0$ есть хоть 1 корень, то возьмём ближайший корень к $\theta_0$ (что делать, если таких корней несчётное число, почему ближайшая к $\theta_0$ точка тоже будет корнем? Потому что $\pd{f}{\theta}$ непрерывна из-за условий регулярности).
		
		\item Если у уравнения правдоподобия нет корней, то доопределим $\wh{\theta}_n := \theta_0$.
	\end{itemize}
	Перейдём к доказательству свойств, а для этого зафиксируем $\eps > 0$ так, что $[\theta_0 - \eps; \theta_0 + \eps] \subset \Theta$. Рассмотрим событие следующего вида:
	\[
		S_n(\theta_0, \eps) := \{x \colon f_{\theta_0 - \eps} < f_{\theta_0}(x_1, \ldots, x_n) \wedge f_{\theta_0}(x_1, \ldots, x_n) > f_{\theta_0 + \eps}(x_1, \ldots, x_n)\}
	\]
	Тогда, в силу уже доказанного экстремального свойства правдоподобия, $\lim_{n \to \infty} P_{\theta_0}(S_n) = 1$. Если $x \in S_n$, то в силу условия регулярности 4 существует точка $\wt{\theta} \in (\theta_0 - \eps; \theta_0 + \eps)$, являющаяся локальным максимумом $f_\theta(x_1, \ldots, x_n, \theta)$. Стало быть, в этой точке $\pd{f_\theta}{\theta}(\wt{\theta}) = 0$. Так как по определению $\wh{\theta}_n(x)$ --- ближайший к $\theta_0$ корень, то $|\wh{\theta}_n(x) - \theta_0| < \eps$. Таким образом:
	\[
		\{\wh{\theta}_n \text{ --- не решение уравнения правдоподобия}\} \subseteq \cX^n \bs S_n
	\]
	Из рассуждений выше мы сразу получаем все утверждения теоремы.
\end{proof}

\begin{note}
	Важно отметить следующие факты о $\wh{\theta}_n$:
	\begin{itemize}
		\item Не факт, что $\wh{\theta}_n$ измерима по $x$
		
		\item Это не оценка, ибо полученное отображение зависит явно от $\theta_0$
		
		\item Если корней несколько, то может быть неясно, какой ближе к $\theta_0$
		
		\item Не обязательно, что корень является глобальным максимумом
		
		\item Корень существует не всегда
	\end{itemize}
\end{note}