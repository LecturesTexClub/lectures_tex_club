\begin{theorem} (о байесовской оценке)
	Байесовская оценка является наилучшей оценкой в байесовском подходе с квадратичной функцией потерь.
\end{theorem}

\begin{theorem} (о наилучшем квадратичном прогнозе)
	Пусть $\xi$ --- случайная величина, $\cC$ --- $\sigma$-алгебра в $\F$. Определим $A = \{\eta \colon \eta \text{ --- $\cC$-измерима}\}$. Тогда
	\[
		\inf_{\eta \in A} \E(\xi - \eta)^2 = \E(\xi - \E(\xi | \cC))^2
	\]
\end{theorem}

\begin{proof}
	Теорема требует разбора случаев:
	\begin{itemize}
		\item $\xi \notin L_2$. Без доказательства
		
		\item $\xi \in L_2$. Нужно добавить и вычесть соответствующий матож в скобке, выделить минимальную часть и показать, что остальное можно либо убрать из-за неотрицательности, либо оно равно нулю:
		\begin{multline*}
			\E(\xi - \eta)^2 = \E(\xi - \E(\xi | \eta) + \E(\xi | \eta) - \eta)^2 =
			\\
			\E(\xi - \E(\xi | \eta))^2 + \E(\eta - \E(\xi | \eta))^2 + 2\E(\xi - \E(\xi | \eta))(\E(\xi | \eta) - \eta)
		\end{multline*}
		Сразу $\E(\eta - \E(\xi | \eta))^2 \ge 0$. Покажем, что правое слагаемое равно нулю:
		\begin{multline*}
			\E(\xi - \E(\xi | \eta))(\E(\xi | \eta) - \eta) = \E\Big(\E\big((\xi - \E(\xi | \eta))(\E(\xi | \eta) - \eta)|\eta\big)\Big) =
			\\
			\E\Big((\E(\xi | \eta) - \eta)\underbrace{\E\big(\xi - \E(\xi | \eta) | \eta\big)}_{0}\Big) = 0
		\end{multline*}
		Отсюда $\E(\xi - \eta)^2 \ge \E(\xi - \E(\xi | \eta))^2$, при этом равенство достигается при $\eta = \E(\xi | \cC)$.
	\end{itemize}
\end{proof}

\begin{proof}
	Пусть $\wh{\theta}(X)$ --- произвольная оценка $\theta$. Тогда, согласно байесовскому подходу, мы минимизируем следующий интеграл:
	\begin{multline*}
		\int_\Theta R(\wh{\theta}(X), t)q(t)d\mu(t) = \int_\Theta \E_t(\wh{\theta}(X) - t)^2q(t)d\mu(t) =
		\\
		\int_\Theta \int_\cX (\wh{\theta}(X) - t)^2f(t, x)d\mu(x)d\mu(\theta) = \E_{\wt{P}} (\wh{\theta}(X) - \theta)^2
	\end{multline*}
	Таким образом, мы минимизируем среднеквадратичное отклонение от функции, зависящей от $X$. Согласно теореме о наилучшем квадратичном прогнозе, оптимальной оценкой будет $\E_{\wt{P}}(\theta | X)$, то есть байесовская оценка.
\end{proof}

\subsection{Проверка гипотезы о независимости выборок}

\begin{problem}
	Есть две выборки одинакового размера: $X = (X_1, \ldots, X_n)$ и $Y = (Y_1, \ldots, Y_n)$. Необходимо проверить гипотезу $H_0 \colon X \indep Y \Lra F_{X, Y}(t, s) = F_X(t) \cdot F_Y(s)$ на уровне значимости $\eps$. Также будем считать, что $\E X_1^2, \E Y_1^2 < \infty$.
\end{problem}

\subsubsection*{Коэффициент корреляции Пирсона}

\begin{definition}
	\textit{Коэффициентом корреляции Пирсона} называется следующая величина:
	\[
		\wh{\rho}(X, Y) = \frac{\sum_{i = 1}^n (X_i - \ol{X})(Y_i - \ol{Y})}{\sqrt{\sum_{i = 1}^n (X_i - \ol{X})^2 \cdot \sum_{i = 1}^n (Y_i - \ol{Y})^2}}
	\]
\end{definition}

\begin{proposition}
	Для коэффициента корреляции Пирсона верна сходимость:
	\[
		\wh{\rho} \xrightarrow[n \to \infty]{\aal{P}} \rho = \corr(X, Y) = \frac{\cov(X, Y)}{\sqrt{DX \cdot DY}}
	\]
\end{proposition}

\begin{proof}
	Как известно, $S_X^2 = \sum_{i = 1}^n (X_i - \ol{X})^2 = \ol{X^2} - (\ol{X})^2$. По УЗБЧ имеем сходимости $\ol{X^2} \to^{\aal{P}} \E X_1^2$ и $\ol{X} \to^{\aal{P}} \E X_1$. Стало быть, $S_X^2 \to^{\aal{P}} DX_1$. Аналогично
	\[
		\sum_{i = 1}^n (X_i - \ol{X})(Y_i - \ol{Y}) = \ol{XY} - \ol{X} \cdot \ol{Y} \xrightarrow[n \to \infty]{\aal{P}} \cov(X_1, Y_1) = \E X_1Y_1 - \E X_1 \E Y_1
	\]
	С использованием теоремы о наследовании сходимости получаем требуемое:
	\[
		\wh{\rho} = \frac{\ol{XY} - \ol{X} \cdot \ol{Y}}{\sqrt{S_X^2 \cdot S_Y^2}} \xrightarrow[n \to \infty]{\aal{P}} \frac{\cov(X, Y)}{\sqrt{DX \cdot DY}} = \rho
	\]
\end{proof}

\begin{theorem} (без доказательства)
	Пусть $n > 2$ и верна гипотеза о независимости выборок, причём они имеют нормальные распределения. Тогда
	\[
		T = \frac{\wh{\rho}\sqrt{n - 2}}{\sqrt{1 - \wh{\rho}^2}} \sim T_{n - 2}
	\]
\end{theorem}

\begin{solution} (Критерий по корреляции Пирсона)
	Если $X, Y$ имеют нормальные распределения, то критерий имеет вид $\{T(x, y) > u_{1 - \eps}\}$, где $u_{1 - \eps}$ --- квантиль $T_{n - 2}$.
\end{solution}

\begin{anote}
	Проблема обычного коэффициента корреляции (Пирсона то есть) состоит в том, что он неустойчив к выбросам в выборке. Для борьбы с этим эффектом далее рассмотрены ещё 2 других коэффициента.
\end{anote}

\subsubsection*{Коэффициент корреляции Спирмена}

\begin{definition}
	\textit{Рангом $X_i$} называется его номер порядковой статистики в выборке $X_1, \ldots, X_n$. Обозначается как $R(X_i)$.
\end{definition}

\begin{note}
	Пусть $(r_1, \ldots, r_n) \in S_n$ --- перестановка. Тогда должно быть понятно, что $P(R(X_1) = r_1 \wedge \ldots \wedge R(X_n) = r_n) = \frac{1}{|S_n|} = \frac{1}{n!}$.
	
	Обозначим $R_i := R(X_i)$. Тогда понятно, что $\ol{R} = \frac{1}{n}\sum_{i = 1}^n R_i = \frac{1}{n}\sum_{i = 1}^n i = \frac{n + 1}{2}$. Более того, мы даже можем явно найти основную часть эмпирической дисперсии $R_i$:
	\[
		\sum_{i = 1}^n (R_i - \ol{R})^2 = \sum_{i = 1}^n \ps{i - \frac{n + 1}{2}}^2 = \frac{n^3 - n}{12} \text{ --- не зависит от перестановки}
	\]
\end{note}

\begin{definition}
	Обозначим $R_i := R(X_i)$ и $S_i := S(Y_i)$. Тогда \textit{коэффициентом корреляции Спирмена} называется следующая величина:
	\[
		\rho_S = \frac{\sum_{i = 1}^n (R_i - \ol{R})(S_i - \ol{S})}{\sqrt{\sum_{i = 1}^n (R_i - \ol{R})^2 \sum_{i = 1}^n (S_i - \ol{S})^2}}
	\]
\end{definition}

\begin{note}
	Естественно, после всего сказанного в замечании выше, возникает вопрос: <<А нельзя ли упростить коэффициент Спирмена?>> Оказывается, можно. Для этого объединим ранги в пары $(R_i, S_i)$. Пусть $T_k$ --- это соответствующий ранг пары $(k, T_k)$. Тогда:
	\begin{multline*}
		\rho_S = \frac{12}{n^3 - n} \sum_{i = 1}^n \ps{R_i - \frac{n + 1}{2}}(S_i - \frac{n + 1}{2}) = \frac{12}{n^3 - n} \sum_{k = 1}^n \ps{k - \frac{n + 1}{2}}\ps{T_k - \frac{n + 1}{2}} =
		\\
		1 - \frac{6}{n^3 - n} \sum_{k = 1}^n (k - T_k)^2 = 1 - \frac{6}{n^3 - n}\sum_{i = 1}^n (R_i - S_i)^2
	\end{multline*}
	
	Отметим, что если верна гипотеза $H_0$, то все перестановки $(T_1, \ldots, T_n)$ равновероятны, а потому $\E T_k = \frac{n + 1}{2}$ и отсюда
	\[
		\E \rho_S = \frac{12}{n^3 - n} \sum_{k = 1}^n \ps{k - \frac{n + 1}{2}}\E \ps{T_k - \frac{n + 1}{2}} = 0
	\]
\end{note}

\begin{proposition}
	Коэффициент корреляции Спирмена обладает следующими свойствами:
	\begin{enumerate}
		\item Если верна гипотеза $H_0$, то $\E \rho_S = 0$ и $D \rho_S = \frac{1}{n - 1}$
		
		\item Коэффициент корреляции Спирмена обладает теми же границами, что и обычная корреляция: $\rho_S \in [-1; 1]$, причём границы достигаются (случаи $R_i = S_i$ и $R_i = n + 1 - S_i$)
		
		\item Если верна гипотеза $H_0$, то распределение $\rho_S$ не зависит от $F_X$ и $F_Y$, его квантили можно найти в статистических таблицах
		
		\item Если верна гипотеза $H_0$, то имеет место сходимость
		\[
			\frac{\rho_S}{\sqrt{D\rho_S}} \xrightarrow[n \to \infty]{d} N(0, 1)
		\]
		При этом можно отметить, что распределение очень похоже на нормальное уже при $n \ge 50$.
	\end{enumerate}
\end{proposition}

\begin{solution} (Критерий по корреляции Спирмена)
	Искомый критерий имеет вид $\{\rho_S > u_{1 - \eps}\}$, где $u_{1 - \eps}$ берётся по таблице.
\end{solution}

\subsubsection*{Коэффициент корреляции Кендалла}

\begin{definition}
	Будем говорить, что пары $(X_i, Y_i)$ и $(X_j, Y_j)$, $i < j$, согласованы, если
	\[
		\sgn(X_i - X_j) \cdot \sgn(Y_i - Y_j) = 1
	\]
\end{definition}

\begin{note}
	В равенстве выше можно оставить только один $\sgn$ (и поместить всё под него), ибо мы всё равно перемножаем знаки.
\end{note}

\begin{note}
	Пусть $S$ --- количество согласованных пар, а $R$ --- остальные. Тогда $S + R = \frac{n(n - 1)}{2}$ --- общее число неупорядоченных пар.
	
	Обозначим $T = S - R = \sum_{i < j} \sgn(X_i - X_j)(Y_i - Y_j)$. Тогда рассуждение выше даёт точные границы $T$: $-\frac{n(n - 1)}{2} \le T \le \frac{n(n - 1)}{2}$.
\end{note}

\begin{definition}
	\textit{Коэффициентом корреляции Кендалла} называется следующая величина:
	\[
		\tau = \frac{T}{\frac{n(n - 1)}{2}}
	\]
\end{definition}

\begin{note}
	Сразу из предыдущего замечания мы получаем границы коэффициента: $\tau \in [-1; 1]$.
\end{note}

\begin{proposition}
	Для коэффициента корреляции Кендалла верны формулы:
	\[
		\tau = \frac{2}{n(n - 1)}(S - R) = 1 - \frac{4R}{n(n - 1)} = 1 - \frac{4}{n(n - 1)}\sum_{i < j} I\{T_i > T_j\}
	\]
	где $T_i$ определяются так же, как и в коэффициенте Спирмена.
\end{proposition}

\begin{proof}
	Все формулы, кроме последней, должны быть понятны: просто подставили $T$ и воспользовались равенством $S + R = \frac{n(n - 1)}{2}$. Нам остаётся показать, что
	\[
		\text{\#несогласованных пар}(X, Y) = \sum_{i < j} I\{T_i > T_j\}
	\]
	Что фактически означает согласованность пар? То, что покоординатные разности имеют одинаковый знак. Этот факт никак не зависит от того, в каком порядке мы рассматриваем пары, поэтому от $(X_i, Y_i)$ можно перейти к парам $(k, T_k)$. Перебором пар с $k_1 < k_2$ мы исчерпаем все варианты, при этом индикатор будет отвечать случаю несогласованности пар.
\end{proof}

\begin{proposition}
	Коэффициент корреляции Кендалла обладает следующими свойствами:
	\begin{enumerate}
		\item Если гипотеза $H_0$ верна, то $\E \tau = 0$ и $D \tau = \frac{2(2n + 5)}{9n(n - 1)}$
		
		\item $\tau \in [-1; 1]$, причём крайние значения достигаются
		
		\item Если гипотеза $H_0$ верна, то распределение $\tau$ не зависит от $F_X$ и $F_Y$, его квантили можно найти в статистических таблицах
		
		\item Если гипотеза $H_0$ верна, то имеет место сходимость
		\[
			\frac{\tau}{\sqrt{D \tau}} \xrightarrow[n \to \infty]{d} N(0, 1)
		\]
	\end{enumerate}
\end{proposition}

\begin{exercise}
	Для коэффициента корреляции Спирмена есть ещё одна формула:
	\[
		\rho_S = 1 - \frac{12}{n^3 - n}\sum_{i < j} (j - i)I\{T_i > T_j\}
	\]
\end{exercise}

\begin{note}
	Таким образом, коэффициент корреляции Кендалла реагирует на ранг в несогласованных парах меньше, чем Спирмена.
\end{note}

\begin{solution} (Критерий по корреляции Кендалла)
	Искомый критерий имеет вид $\{\tau > u_{1 - \eps}\}$, где $u_{1 - \eps}$ берётся по таблице.
\end{solution}