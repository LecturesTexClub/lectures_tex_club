\begin{definition}
	Наилучшая оценка для $\tau(\theta)$ в классе $\cK$ называется \textit{оптимальной оценкой}.
\end{definition}

\begin{definition}
	Статистика $S(X)$ называется \textit{полной для параметра $\theta$}, если верна импликация:
	\[
		\forall f\ \ \Big(\forall \theta \in \Theta\ \ \E_\theta f(S(X)) = 0\Big) \Ra \Big(\forall \theta \in \Theta\ \ f(S(X)) =\aal{P_\theta} 0\Big)
	\]
\end{definition}

\begin{theorem} (Лемана-Шеффера об оптимальной оценке)
	Пусть $T$ --- полная достаточная статистика для параметра $\theta$, $d(X)$ --- несмещённая оценка $\tau(\theta)$. Тогда:
	\begin{enumerate}
		\item $\phi(T(X)) = \E_\theta (d(X) | T(X))$ --- несмещённая оценка с равномерно минимальной дисперсией для $\tau(\theta)$
		
		\item Если дополнительно $D_\theta \phi(T(X)) < \infty$, то $\phi(T(X))$ является оптимальной оценкой
	\end{enumerate}
\end{theorem}

\begin{proof}~
	\begin{enumerate}
		\item По теореме Колмогорова-Блэквелла-Рао мы уже знаем, что $\phi(T(X))$ --- несмещённая оценка, которая как минимум не хуже $d(X)$ по дисперсии. Пусть $\wt{d}(X)$ --- тоже несмещённая оценка. По той же теореме мы можем построить $\wt{\phi}(T(X)) = \E(\wt{d}(X) | T(X))$ с аналогичными свойствами. Теперь осталось заметить, что для $h = \phi - \wt{\phi}$ матожидание $h(T(X))$ нулевое:
		\[
		\forall \theta \in \Theta\ \ \E_\theta h(T(X)) = \E_\theta (\phi(T(X)) - \wt{\phi}(T(X))) = \tau(\theta) - \tau(\theta) = 0
		\]
		Так как $T(X)$ --- полная статистика, то это автоматически означает $\phi(T(X)) =\aal{P_\theta} \wt{\phi}(T(X))$. Отсюда следует, что для любой несмещённой оценки мы умеем строить её улучшение, которое точно не лучше $\phi(T(X))$. Это означает, что у $\phi(T(X))$ равномерно минимальная дисперсия среди всего класса несмещённых оценок.
		
		\item Теперь у нас ещё есть условие, что $D_\theta \phi(T(X)) < \infty$. Если теперь какая-то оценка $\wt{d}(X)$ имеет ровно ту же дисперсию при всех $\theta \in \Theta$, то по теореме Колмогорова-Блэквелла-Рао это возможно тогда и только тогда, когда $\wt{d}(X) =\aal{P_\theta} \phi(T(X))$. С учётом предыдущего результата, оценка $\phi(T(X))$ становится оптимальной.
	\end{enumerate}
\end{proof}

\begin{corollary}
	Если $T(X)$ --- полная достаточная оценка для параметра $\theta$, а $\phi(T(X))$ --- несмещённая оценка $\tau(\theta)$, то
	\begin{enumerate}
		\item $\phi(T(X))$ не хуже остальных оценок класса $\cK$
		
		\item Если $\phi(T(X)) \in L_2$, то $\phi(T(X))$ является оптимальной оценкой $\tau(\theta)$
	\end{enumerate}
\end{corollary}

\begin{proof}
	В рамках доказанной теоремы, положим $d(X) = \phi(T(X))$. Но тогда $\psi(T(X)) = \E(\phi(T(X)) | T(X)) = \phi(T(X))$, коль скоро $\phi(T(X))$ является $T(X)$-измеримой, а значит все свойства далее доказаны уже по теореме.
\end{proof}

\begin{theorem} (об экспоненциальном семействе)
	Пусть $\{X_i\}_{i = 1}^n$ --- выборка из экспоненциального семейства с плотностью общего вида:
	\[
		p_\theta(x) = h(x)\exp\ps{\sum_{i = 1}^k a_i(\theta)T_i(x) + V(\theta)}
	\]
	Тогда, если область значений векторной функции $\vv{a}(\theta) = (a_1(\theta), \ldots, a_k(\theta))^T, \theta \in \Theta$ содержит $k$-мерный параллелепипед, то \textcolor{red}{внезапно, вектор стал оценкой скаляра}
\end{theorem}

\begin{note}
	Мы доказали достаточно много хороших фактов про наличие и выражение оптимальной статистики. Из них можно получить некоторый общий алгоритм поиск оптимальной статистики:
	\begin{enumerate}
		\item Найти достаточную статистику $T$
		
		\item Проверить эту статистику на полноту
		
		\item Если всё верно, то нужно решить уравнение вида $\E_\theta g(T(X)) = \tau(\theta)$, которое ещё называют \textit{уравнением несмещённости}
	\end{enumerate}
\end{note}

\subsection{Доверительные интервалы}

\subsubsection{Основные определения}

\begin{note}
	Далее мы находимся в вероятностно-статистическом пространстве $(\cX, \B(\cX), \cP)$, $\cP = \{P_\theta, \theta \in \Theta\}$ и рассматриваем наблюдение $X$ с неизвестным распределением $P \in \cP$.
\end{note}

\begin{definition}
	Пара статистик $(T_1(X), T_2(X))$ называется \textit{доверительным интервалом уровня доверия $\gamma$ для параметра $\theta$}, если выполнено неравенство:
	\[
		\forall \theta \in \Theta\ \ P(T_1(X) < \theta < T_2(X)) \ge \gamma
	\]
	Причём, если при всех $\theta \in \Theta$ достигается равенство, то доверительный интервал называется \textit{точным}.
\end{definition}

\begin{note}
	На практике интересуют уровни $\gamma \in \{0.9, 0.95, 0.99\}$. Также иногда удобно использовать односторонние доверительные интервалы вида $(-\infty, T_2(X))$ или $(T_1, +\infty)$.
\end{note}

\begin{note}
	В многомерном случае $\theta \in \Theta \subseteq \R^k$ можно определить аналогичное понятие доверительного интервала для $\theta_i$ или скалярной функции $\tau(\theta)$.
\end{note}

\begin{definition}
	Множество $S(X) \subseteq \Theta$ называется \textit{доверительным множеством уровня доверия $\gamma$ для параметра $\theta$}, если выполнено неравенство:
	\[
		\forall \theta \in \Theta\ \ P_\theta(\theta \in S(X)) \ge \gamma
	\]
\end{definition}

\begin{anote}
	Да, множество зависит от выборки.
\end{anote}

\subsubsection{Метод центральных статистик}

\begin{definition}
	Пусть одномерная функция $G(x, \theta)$ такова, что распределение $G(X, \theta)$ не зависит от параметра $\theta$ (другими словами, при любом фиксированном $\theta \in \Theta$ распределение статистики $G(X, \theta)$ остаётся неизменным). Тогда $G(X, \theta)$ называется \textit{центральной статистикой}.
\end{definition}

\begin{anote}
	Название тут несколько противоречивое, как и в случае упорядоченного множества: центральная статистика сама по себе не является статистикой, однако при каждом фиксированном $\theta$ --- да.
\end{anote}

\begin{example}
	Пусть $X_i \sim N(\theta, 1)$, $\theta \in \R$. Построим доверительный интервал для $\theta$ с уровнем доверия $\gamma$. За счёт УЗБЧ и ЦПТ мы имеем 2 прекрасных факта:
	\begin{itemize}
		\item $\ol{X} = \frac{1}{n}\sum_{i = 1}^n X_i \sim N(\theta, 1 / n)$
		
		\item $\sqrt{n}(\ol{X} - \theta) \sim N(0, 1)$ (Действительно, $\ol{X} \sim N(\theta, 1 / n)$, тогда $\ol{X} - \theta \sim N(0, 1 / n)$ ну и домножение нормирует дисперсию)
	\end{itemize}
	Во втором факте оценка не зависит от $\theta$, этим мы и воспользуемся. Пусть $u_p$ --- $p$-квантиль $N(0, 1)$. Тогда мы можем сказать следующее про интервал $\sqrt{n}(\ol{X} - \theta)$:
	\[
		\forall \theta \in \Theta\ \ P_\theta(u_{\frac{1 - \gamma}{2}} < \sqrt{n}(\ol{X} - \theta) < u_{\frac{1 + \gamma}{2}}) = P_\theta(|\sqrt{n}(\ol{X} - \theta)| < u_{\frac{1 + \gamma}{2}}) = \gamma
	\]
	Неравенство можно переписать так, чтобы $\theta$ оказалось посередине. Это же даст нам вид оценок:
	\[
		 \ol{X} - \frac{u_{\frac{1 + \gamma}{2}}}{\sqrt{n}} < \theta < \ol{X} - \frac{u_{\frac{1 - \gamma}{2}}}{\sqrt{n}}
	\]
	Итак, доверительный интервал --- это $\ps{\ol{X} - \frac{u_{\frac{1 + \gamma}{2}}}{\sqrt{n}}, \ol{X} - \frac{u_{\frac{1 - \gamma}{2}}}{\sqrt{n}}}$
\end{example}

\begin{note}
	Пример выше, по факту, показал применение центральной статистики, где можно отделить $X$ от $\theta$. В общем случае, пусть у нас есть центральная статистика $G(X, \theta)$, $\gamma_{1, 2} \in (0; 1) \colon \gamma_2 - \gamma_1 = \gamma$, а также $g_i$ --- обозначение $\gamma_i$-квантиля для функции распределения $G(X, \theta)$ при фиксированном $\theta$. Тогда:
	\[
		\forall \theta \in \Theta\ \ P_\theta(g_1 \le G(X, \theta) \le g_2) \ge \gamma_2 - \gamma_1 = \gamma
	\]
	Это, увы, не доверительный интервал. Однако, мы можем построить доверительное множество $S(X) = \{\theta \in \Theta \colon g_1 \le G(X, \theta) \le g_2\}$. Тогда сразу имеем требуемое:
	\[
		\forall \theta \in \Theta\ \ P_\theta(\theta \in S(X)) = P_\theta(g_1 \le G(X, \theta) \le g_2) \ge \gamma
	\]
\end{note}

\begin{note}
	Есть так называемые \textit{статистические таблицы}. Когда нужны конкретные квантили $g_1, g_2$, их обычно можно найти там.
\end{note}

\begin{note}
	Следующая лемма и её следствия будут посвящены понятному вопросу: <<А как искать центральные статистики?>>
\end{note}

\begin{lemma}
	Пусть $\{X_i\}_{i = 1}^n$ --- выборка со строго возрастающей функцией распределения $F$. Если $F$ непрерывна, то
	\[
		G(X_1, \ldots, X_n) = -\sum_{i = 1}^n \ln F(X_i) \sim \Gamma(1, n)
	\]
\end{lemma}

\begin{proof}
	Во-первых, покажем, что $F(X_i) \sim U[0; 1]$. Действительно:
	\[
		\forall y \in (0; 1)\ \ P(F(X_i) \le y) = P(X_i \le F^{-1}(y)) = F(F^{-1}(y)) = y
	\]
	Стало быть, $-\ln F(X_i) =^d -\ln U[0; 1] \sim Exp(1)$, а в силу свойства сложения случайных величин с экспоненциальным распределением получаем требуемое.
\end{proof}

\begin{corollary}
	Если $\{X_i\}_{i = 1}^n$ --- выборка из распределения $P_\theta$, причём при любом $\theta \in \Theta$ функция распределения $F_\theta(x)$ непрерывна и строго возрастает по $x$, то
	\[
		G(X_1, \ldots, X_n, \theta) = -\sum_{i = 1}^n \ln F_\theta(X_i) \text{ --- центральная статистика}
	\]
\end{corollary}

\begin{definition}
	Пусть $\{X_n\}_{n = 1}^\infty$ --- выборка из распределения $P_\theta$. Последовательность пар статистик $(T_{n, 1}(X), T_{n, 2}(X))$ называется \textit{асимптотическим доверительным интервалом уровня доверия $\gamma$ для параметра $\theta$}, если выполнено неравенство:
	\[
		\forall \theta \in \Theta\ \ \varliminf_{n \to \infty} P\big(T_{n, 1}(X) < \theta < T_{n, 2}(X)\big) \ge \gamma
	\]
	Причём если для всех $\theta \in \Theta$ достигается равенство, то асимптотический доверительный интервал называется \textit{точным}.
\end{definition}

