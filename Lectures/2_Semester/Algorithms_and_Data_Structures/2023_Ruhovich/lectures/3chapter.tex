\section{Splay-Дерево}



Splay дерево -- еще одно двоичное дерево поиска, в котором все операции работают за $O(log_2(n))$, причем амортизированно. Крутость его заключается в том, что нет никаких инвариантов на структуру дерева, в отличие от предыдущих ДДП, которые мы изучили. Придумали его примерно через 20 лет после открытия первого ДДП (AVL), и оказалось, что очень часто им можно заменить другие ДДП в различных задачах.

Асимптотику докажем по-хитрому: пусть в каждой вершине $v$ записан вес $w_v > 0$. Пусть $W = \Sigma_{v \in V} w_v$ (где $V$ -- множество всех вершин). Тогда докажем, что учетная стоимость любой операции равна $O(log_2(\frac{W}{w_i}))$, где $i$ -- вершина, с которой мы работали.

\begin{example}
    Рассмотрим, для простоты, операцию $search$. Если мы вызвали ее $p_i$ раз от $i$-й вершины, то время работы будет $p_1 log_2(\frac{W}{w_1}) + p_2 log_2(\frac{W}{w_2}) + \cdots + p_n log_2(\frac{W}{w_n})$. Фишка в том, что все $w_i$ мы вводим самостоятельно. Если, например, $w_i = p_i$ и $\Sigma_{i = 1}^{n} p_i = 1$, то время работы $p_1 log_2(\frac{1}{p_1}) + \cdots + p_n log_2(\frac{1}{p_n})$.
\end{example}
% Не понял, как мы говорим, что сумма всех p_i равна 1. И вообще, зачем это надо, если даже без этого там получается n log n?


\subsection{Операции в Splay-дереве}


\begin{definition}
    $Splay(v)$ -- операция, которая делает серию поворотов таким образом, что $v$ поднимается на место корня.
\end{definition}

Тут возникает еще одно преимущество -- вершинки, к которым обращались недавно, будут находиться ближе к корню, что похоже на то, как работает кэш. \\
Все остальные операции мы будем делать через $splay$, а потом докажем, что он работает амортизированно за $O(log_2(n))$, тогда и все операции будут работать за $\Theta(splay)$.




Реальное время работы будет thetta(depth + 1), учетное: $\theta(log W/w_i + 1)$. Предположим, что есть вот такой мистический Splay. Тогда за такое же учетное время можно реализовать search. Если нам дали ключ и мы его хотим найти, просто будем идти по дереву и вызовем от него Splay (а если не нашли, то вызовем от последней вершины), тогда search будет работать за время сплея. Так же легко можно сделать $get\_min$ и $get\_max$. Но вот для других операций все не так просто - чтобы узнать, что какие-то доп операции не ломают потенциал, нужно его ввести и исследовать (например, чтобы узнать, что подвешивание поддерева, merge и т. д. работают нормально). Давайте введем понятие $S_v := sum for u \in subtree(v) w_u$. Мистический потенциал $\Phi_T := sum for v \in T: log_2(S_v)$. В простой версии док-ва у нас были бы веса 1, и $S_v = sz_v$, а потенциал это примерно n log n. Возникает проблема - $w_i$ может быть меньше 1, тогда и потенциал может быть меньше 0. Тогда просто скажем, что $w_i$ >= 1. 

Кстати, мы не обсудили, как сливать ДДП по явному ключу, но на самом деле так же, как по неявному, но с оговоркой - веса каждой вершинки из левого дерева должны быть меньше, чем веса вершинок из правого дерева.

Давайте обсудим, как делать Merge. У левого дерева давайте вызовем сплей от самого правого сына, таким образом, у корня будет только левое поддерево, а в качестве правого сына повесим туда правого дерево. Тогда время работы splay(max) + O(1), но какая же учетная асимптотика? Допустим веса W1 < W2, и сплей сработал за 1 + $log(W_1/w_max)$, а подвешивание, заметим, поменяло потенциал только у корня. В корне стало $1 = log_2(W1 + W2) - log_2(W1) = 1 + log_2((W1 + W2)/W1)$. Тогда все время работы merge: $\Theta(1 + log_2((W_1 + W_2)/W_max))$. Тогда можно легко делать erase - сделаем от него Splay, просто удалим вершинку из корня и смерджим детей. Как же делать split? Просто найдем граничный элемент, сделаем от него сплей, и отпилим от него правого ребенка (и получим как раз два нужных дерева). Потенциал только умнеьшится, так что все ок. Время работы: $\Theta(1 + log_2(W/w_key))$. 
 
Все остальные операции уже можно сделать с помощью split и merge. Но давайте подумаем, как быстро делать, например, $lower\_bound$. Если будем как в обычном ДДП идти до нужной вершины и делать сплей, то во-первых, в корне может быть другая вершина, а во-вторых, время работы будет $1 + log_2(W/w_i) + log_2(W/w_{lower_bound_key})$. Но на самом деле второе слагаемое можно убрать - мы как-будто бы сделали сплит (это все нужно чтобы делать split по значению, а не по вершине).

Давайте научимся делать Insert быстрее, чем просто split и 2 merge. Пусть было 2 дерева с весами W1 и W2. Что будет, если завести новый корень весом $w_v$ и подвесим к нему эти 2 дерева? [[[Тогда потенциал изменится на $1 + log_2(W/w_i) + 1 + log_2(W + W_v)$.]]] Тогда все можно сделать за $1 + log_2(W/w_i) + 1 + log_2((W1 + w_v)/w_j) + 1 + log_2((W1 + W_v + W2)/w_k)$.

\subsubsection{Операция splay(x)}

Теперь давайте разберемся, как работает $splay(x)$ и докажем его асимптотику. Рассмотрим 4 (3) случая:

\begin{enumerate}
    \item[0.] $v$ -- корень \\
        Дерево [картинка до/после]
    \item[1.] $zig$: $v$ -- не корень, но сын корня \\
        Тогда просто сделаем малый поворот по ребру к предку. [картинка до/после]
    \item[2.] $zig-zig$: $v$ и его родитель $p$ оба левые или правые дети \\
        Обычные повороты делают родителей детьми, а мы сделаем дедушку внуком. Сделаем что-то типо ``длинного поворота'' -- корень будет $v$, его ребенком с другой стороны от изначальной будет $p$, а потом бывший корень. Заметим, что если сделать 2 левых поворота, то дедушка будет сыном, а не внуком, и будет лажа [картинка до/после]
    \item[3.] $zig-zag$: $v$ и его родитель $p$ являются детьми с разных сторон \\
        Просто сделаем большой поворот, тогда папа и дедушка будут детьми $v$. [картинка до/после]
\end{enumerate}


Докажем время работы. \\
Случай 0: учетное время любое -- $O(1)$, $O(0)$ -- все, что угодно \\
Для шагов 1-3 хотим доказать, что их учетная стоимость не превосходит $3(log_2(S_{v, new}) - log_2(S_{v, old})) + Z$, где $Z = 1$, если это операция $zig$ и 0 иначе. Если мы это докажем, то сразу докажем и учетное время $splay(x)$, т. к. там выйдет телескопическая сумма где все сократится, и в итоге будет $3(log_2(S_{v, final}) - log_2(S_{v, start})) + 1 \leq 3(log_2(W) - log_2(w_v)) + 1 = 3log_2(W/w_i) + 1$.

\begin{enumerate}
    \item Учетная стоимость шага $zig$ \\
        Пусть в корне стояла вершина $u$. По определению, стоимость это единица плюс разность потенциала в конце с потенциалом в начале, что равно $1 + log_2(S_{v, after}) + log_2(S_{u, after}) - log_2(S_{v, before}) - log_2(S_{u, before})$. Заметим, что $S_{v, after} = S_{u, before}$, тогда стоимость равна $1 + log_2(S_{u, after}) - log_2(S_{v, before}) \leq 1 + log_2(S_{v, after}) - log_2(S_{v, before}) \leq 1 + 3(log_2(S_{v, after}) - log_2(S_{v, before}))$.
    \item Учетная стоимость шага $zig-zig$ \\
        $1 + log_2(S_{v, after}) + log_2(S_{A, after}) + log_2(S_{B, after}) - log_2(S_{v, before}) - log_2(S_{A, before}) - log_2(S_{B, before})$. Если бы не единичка, мы бы могли втупую все оценить как одинаковые слагаемые, но тут придется делать по-другому. Давайте тоже сократим то, что очевидно было равно, тогда прошлое выражение равняется $1 + log_2(S_{A, after}) + log_2(S_{B, after}) - log_2(S_{v, before}) - log_2(S_{A, before}) \leq 1 + log_2(S_{v, after}) + log_2(S_{B, after}) - log_2(S_{v, before}) - log_2(S_{v, before}) = 1 + log_2(S_{v, after}) + log_2(S_{B, after}) + log_2(S_{v, before}) - 3log_2(S_{v, before})$. \\
        Т. к. логарифм - выпуклая вверх функция, то $\frac{(log(x_1) + log(x_2))}{2} \leq log(\frac{(x_1 + x_2)}{2})$. \\
        Тогда $1 + log_2(S_{v, after}) + log_2(S_{B, after}) + log_2(S_{v, before}) - 3log_2(S_{v, before}) \leq 1 + log_2(S_{v, after}) + 2log_2(\frac{(S_{B, after} + S_{v, before})}{2}) - 3log_2(S_{v, before}) = 1 + log_2(S_{v, after}) + 2log_2(S_{B, after} + S_{v, before}) - 2 - 3log_2(S_{v, before})$; Заметим, что $S_{B, after} + S_{v, before} \leq S_{v, after}$. Тогда выражение выше не превосходит $3log_2(S_{v, after}) - 3log_2(S_{v, before}) - 1$.
    \item Учетная стоимость шага $zig-zag$ \\
        $1 + log_2(S_{v, after}) + log_2(S_{A, after}) + log_2(S_{B, after}) - log_2(S_{v, before}) - log_2(S_{A, before}) - log_2(S_{B, before}) = 1 + log_2(S_{A, after}) + log_2(S_{B, after}) - log_2(S_{v, before}) - log_2(S_{A, before}) \leq 1 + 2log_2(\frac{(S_{A, after} + S_{B, after})}{2}) - 2log_2(S_{v, before}) \leq 2log_2(S_{v, after}) - 1 - 2log_2(S_{v, before}) \leq 3(log_2(S_{v, after}) - log_2(S_{v, before}))$.
\end{enumerate}

Таким образом, мы доказали Splay, а следовательно и все Splay-Tree.



\section{LCA}




Все изученные деревья являются так называемыми "split-merge tree" (такого термина нет). Заметим, что с такими операциями в неявном дереве можно еще и делать k-тую порядковую статистику, циклический сдвиг на k элементов, присваивание элемента и т. д.. Допустим мы хотим искать сумму на подотрезке. Тогда просто сделаем сплиты чтобы получить нужный подотрезок, берем сумму (которую заранее храним и обновляем) и потом мерджим все обратно. Еще можно сделать ДО, где будем поддерживать массовые операции (в том числе и присваивание на подотрезке). Логика такая: если в вершинке надо поменять что-то во всем ее поддереве, то просто поймем, что мы же операции делаем сверху, поэтому можно просто запомнить, что мы должны там все поменять, и в следующих операциях, когда нам нужно будет это поддерево, мы применим эти изменения. Отличия в коде только в том, что когда идем в низ всегда делаем pushDown. Теперь, кстати, можно еще и делать reverse на подотрезке (в неявных ДДП).
Теперь попробуем сделать все эти операции для массива на дереве.
Анекдот: А что такое дерево? Ну вот это АВЛ дерево, красно черная дерева, сплея-мана дерева...

Пусть у нас есть обычное подвешенное дерево (не обязательно двоичное). Пусть в каждой вершине хранится число (произвольное). Допустим дерево фиксированное. И мы хотим тут делать всякие операции, например сумма на подотрезке, но что это такое? Пусть это будет путь от u до v. Для этого можно посчитать так называемые "префиксные суммы", только вот префиксные суммы чего? Еще мы хотим присваивать на пути, и вообще все, что умеет дерево отрезков, и более того - за O(log n). Пусть дерево подвешено за root. Начнем с простой операции - isAncestor(u, v). Тут возникает классическая технология timeIn и timeOut, которую считаем пока неизвестным для нас DFS-ом. [картинка с временами]. Тогда есть утверждение: u предок v <=> временной подотрезок u является "надотрезком" отрезка v. Такое наблюдение позволяет нам сделать предпосчет за O(n) и отвечать на запрос за O(1). 
Теперь введем мистическую операцию LCA (Lowest Common Ancestor) - самая глубокая вершина, которая является предком и вершины u, и вершины v. Есть два способа - оба требуют предпосчет O(n log n), но один ищет LCA за O(log n), а другой за O(1), при этом нам пригодятся оба способа не смотря на то, что один выглядит явно быстрее другого. Для начала для посчитаем up[v][l] - предок вершины v на расстоянии $2^l$ или root, посчитать это все можно за O(n log n) используя тот факт, что up[v][l+1] = up[up[u][l]][l]. 
Чтобы найти LCA для начала за O(1) поймем, является ли одна вершина предком другой. Если да, то просто вернем ее. Если нет, то будем подниматься из вершины u так, чтобы не стать предком вершины v. 
for l = LOG..0:
	if (!isAncestor(up[u][l], v)):
		u = up[u][l];

После такого u окажется не в LCA, а за 1 шаг до LCA, то есть вернуть можно просто ее предка.

Альтернативная реализация:
Пусть у нас будет такая функция goUp(u, h) - подняться вверх от u на высоту h. Тогда:
LCA(u, v):
	if h(u) < h(v):
		swap(u, v);
	u = goUp(u, h);
	if (u == v):
		return u;
	for l = LOG...0:
		if (up[u][l] != up[v][l]):
			v = ..., u = ...

Тут можно искать минимум/максимум на пути - поднимаемся из обоих вершинок до LCA и поддерживанием минимум/максимум. Искать сумму все же удобнее предыдущим способом.

timeIn похоже на preOrder, timeOut похоже на pastOrder. Давайте сделаем так называемый "inOrder" - и сведем задачу поиска чего-либо на пути в дереве к задаче поиска чего-либо на подотрезка в массиве. В этом обходе пишем сначала себя, потом каждого ребенка, и после каждого ребенка пишем снова себя. Если мы в этом списке вместо самих вершинок напишем глубины этих вершинок. Оказывается, что если написать этот список, и уметь искать минимум на подотрезке, то мы можем искать LCA за O(1). Для этого найдем первое вхождение первой вершины, первое вхождение второй вершины (с помощью timeIn), и найдем вершину с минимальной глубиной на этом отрезке (с помощью Sparse Table за O(1)). В качестве упражнения нужно доказать, что это и будет LCA. 

Пусть у нас есть фиксированное дерево и мы хотим находить сумму на пути. Кто-то побежит писать HLD, но мы можем это сделать даже без двоичных подъемов - давайте для каждой вершины (preOrder обходом) посчитаем сумму на пути от нее до корня (если корня нет, то сделаем корнем произвольную вершину). Тогда sum(u, v) = sum(u) + sum(v) - 2 * sum(LCA(u, v)) + value[LCA(u, v)]. 
Что если нам теперь нужно уметь делать assign(v, x)? Заметим, что если мы поменяли элемент, то нам нужно просто уметь делать прибавление на поддереве. Для этого заметим, что если мы сделаем preOrder обход и пронумеруем все вершины, то поддерево это подотрезок, тогда прибавить на поддереве = прибавить на подотрезке с помощью, например, ДО. К сожалению, это теперь работает за O(log n), а не за O(1). Но такой технологией можно делать очень ограниченное число технологий. Например еще можно как-то сделать max(u, v) с помощью двоичных подъемов, но если добавить assign(u, x) - то уже ничего не выйдет. Тут нам нужна более продвинутая технология.




\section{Heavy-Light Decomposition}




Слово "декомпозиция" подразумевает, что мы дерево будет на что-то декомпозировать. Этим "что-то" будут пути, сейчас выясним на какие.
У каждого поддерева есть его размер, или же sz(v).
Опр. Пусть (u, v) - ребро дерева, и u - родитель. Тогда (u, v) - ТЯЖЕЛОЕ (красным), если sz(v) >= sz(u)/2, и ЛЕГКОЕ(синим) иначе.
Утв. Любой вершине u инцидентно не более одного тяжелого ребра. "Основная красота этого утверждения в том, что это чистейшая брехня". Правильно было бы сказать:
Утв. Любой вершине u инцидентно не более одного тяжелого ребра, ведущего в ребенка. [картинка графа, где отмечены тяжелые и легкие ребра]

Собственно HLD - представление вершины в виде какого-то тяжелого пути, при этом на каждом пути будем хранить реальное ДО. Для изменения просто изменим вершину в нужной ДОшке, чтобы найти сумму можно найти sum(u, LCA(u, v)) и sum(v, LCA(u, v)). Пусть вершина u лежит на каком-то тяжелом пути, который где-то заканчивается. Тогда в ДОшке возьмем нужную сумму, а легкие ребра сложим руками, и переберем все такие тяжелые пути. Тогда время работы O(logn * cntLight) (обращаемся к ДОшке за O(log n) после каждого раза, когда встречаем синее ребро в худшем случае). FunFact: кол-во красных путей на отрезке равно +- 1 от кол-ва легких ребер.
Мистический факт: для любой вершины v на пути от v до корня не более чем $log_2(n)$ легких ребер. Пусть мы идем от корня до вершины, каждый раз проходя по легкому ребру sz увеличивается не более чем в 2 раза, а по тяжелому не менее. 
Тогда HLD работает за $O(log^2(n))$ и мы теперь умеем делать на пути все, что умело ДО на отрезке. Чтобы допилить до O(log n) сделаем на пути вместо ДО некоторую модификацию ДО. Пусть у нас есть красный путь, и на каждой вершине висит какое-то дерево с размерами s1, s2, ..., sk (размер без учета размера от тяжелого ребенка). Из этого красного пути сделаем ДДП. Для этого найдем такую позицию i, что если S := сумма всех sz всего поддерева, то $s1 + \cdots + s_{i-1} < S/2 <= s1 + \cdots + si$. ((((тут не понял про S))))
Теперь пусть i объявляется корнем этого ДДП, и на каждого подотрезке считаем сумму точно таким же образом. Заметим, что в дереве почти всегда нам нужна просто сумма на префиксе. Тогда по аналогии с задачкой "в массиве из 0 и 1 поддерживать операцию изменения числа и найти k-тую единицу на отрзке" будем делать бин поиск по ДДП за log(n), а не за $log^2(n)$. 
Докажем, что суммарно спустимся мы O(log n) раз в дереве. Пусть есть какие-то пути отделенные синими ребрами. Пусть на первом пути m вершин. Для начала найдем центр этого пути. Он лежит на нашем пути? Если нет, то выкидываем его и правое (лишнее) поддерево из рассмотрения (и заметим, что мы выкинули как минимум m/2 вершин). Если да, то выкидываем из рассмотрения ее и то, что левее (добавляя за O(1) эту сумму к ответу). Тогда каждый спуск уменьшает m в два раза, и пусть мы наконец-то пришли в вершину, у которой есть далее на пути синее ребро (то есть она в корне нашего ДДП). В этот момент мы точно уменьшаемся (потому что от нее мы идем в ребенка), и там уже будет висеть например m1 вершин. Далее отпиливаем, остается m1/2 вершин и т. д.. Тогда каждый раз у нас кол-во актуальных вершин уменьшается в 2 раза, тогда суммарное время спуска будет O(log n). Давайте это докажем.
Возьмем этот красный путь, на котором построено ДДП. На каждой вершине висит что-то синее. Изначально у нас актуальны все вершины, если мы пойдем, например, влево - то актуальными станут только те вершины, которые были слева. Актуальных вершин тогда стало как минимум в 2 раза мнеьше, чем неактуальных. На следующем шаге тоже уменьшаться в 2 раза, и так далее. После этого мы в глобальном поддереве перешли в вершину по легкому ребру и обнаружили там еще один тяжелый путь. Теперь актуальные вершины тоже висят везде, и мы помним, что все это - это все еще часть той одной вершинки из первого тяжелого пути. Теперь опять каждый шаг мы уменьшаем кол-во актуальных вершин в 2 раза, дошли до одной оставшейся вершинки, и в следующем красном пути у нас все вершинки будут частью текущего поддерева. То есть за каждый шаг мы уменьшаем глобальное кол-во актуальных вершин в 2 раза, а синих ребер не более чем логарифм, тогда мы можем в HLD спускаться и полностью делать все ДОшные операции за O(log n), ЧТД.




\section{Level Ancestor Queries}




Рассмотрим еще одну "красивую" задачу: Level Ancestor Queries. Задача простая: дано дерево, и нужно делать только goUp(u, h). С помощью бинапов можем сделать предпосчет за O(n log n), а подъем за O(log n). Наша цель на сегодня: хотя бы сделать подъем за O(1). Забудем про HLD и изучаем Longest Path Decomposition = LPD. У нас есть подвешенное дерево, и у каждой вершины у которой есть дети хотим выделить 1 ребро в ребенка. Кстати, есть интересная версия HLD, где тяжелое ребро ведет в самое тяжелое поддерево, это удобнее писать и можно написать всего одно ДО. Здесь же давайте выделять ребра в самое глубокое поддерево. [картинка с глубинами и ребрами]
Анекдот: Дорогие дети, а насколько глубоко я могу в вас войти?
LPD приятен тем, что его можно построить за линию и ровно теми же способами искать сумму на отрезке. Но оказывается, что на пути от вершины до корня обычных ребер не более чем 2sqrt(n). Дело в том, что пройдя по обычному ребру, если было число x, то будет написано число хотя бы x+1. Заметим, что можно ответвлиться и пойти в другую глубину на глубину x+1. Далее будет x+2 и поддерево, куда можно пойти еще на x+2 вершины. Тогда мы встретим хоты бы 0, >= 1, >= 2, ..., >= k. Тогда еще есть вершин 1, >= 2, >= 3, ..., >= k+1, тогда n >= 1 + 2 + .. + k + k+1 = (k+1)(k+2)/2 => k <= 2sqrt(n).
Задачка: как превратить n предпосчета и sqrt(n) на запрос в n предпосчета и log n на запрос? Тут нам нужна другая декомпозиция. Она на самом деле не является декомпозицией, но называется так: "Лестничная декомпозиция" (Ladder Decomposition).

\subsection{Ladder Decomposition}

Давайте заметим, что если предпосчет работает не за n, а за 2n, то все еще все будет круто. Давайте просто на каждом пути из k вершин добавим еще k вершин. Все равно строим все за линию, но теперь подниматься нужно и по пути Longest Path'а, но еще и по нашей добавке. Но если глубина вершины x, то глубина ее предка >= x + 1. Заметим, что длина нашей добавки до следующего красного ребра хотя бы x, тогда глубина в вершинке около следующего красного пути >= 2x. Теперь для нужной асимптотики насчитаем Ladder Decomposition и бинарные подъемы. Тогда если из вершины v хотим подняться на высоту h. Давайте поднимемся на максимальную степень двойки которая не превосходит h за O(1) (то есть поднимаемся на высоту хотя бы половины h). Теперь нам надо подняться еще на высоту h'. Но заметим, что $2^l$ > h', тогда у этого поддерева глубина хотя бы h', тогда с помощью Ladder Decompostition мы поднимемся вверх за O(1).