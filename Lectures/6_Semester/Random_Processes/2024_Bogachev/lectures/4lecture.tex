\begin{reminder}
	\textit{Характеристической функцией случайного вектора $\xi$} называется функция, заданная следующим образом:
	\[
		\phi_\xi(y) = \E e^{i(y, \xi)}
	\]
	В частности, для случайной величины $\xi$:
	\[
		\phi_\xi(y) = \E e^{iy\xi}
	\]
\end{reminder}

\begin{reminder}
	Если $\xi \indep \eta$, то $\phi_{\xi + \eta} = \phi_\xi \cdot \phi_\eta$
\end{reminder}

\begin{note}
	Критерий Колмогорова о существовании процесса с заданными распределениями (теорема \ref{proc_existence_crit}) можно переписать в терминах характеристических функций:
	
	Пусть $T \subseteq \R$ и при всех $t_1 < \ldots < t_n$ заданы меры $P_{t_1, \ldots, t_n}$ на $(\R^n, \B(\R^n))$, причём им соответствуют характеристические функции $\phi_{t_1, \ldots, t_n}$. Тогда, существование процесса с конечномерными распределениями $P_{t_1, \ldots, t_n}$ эквивалентно условию:
	\[
		\forall m \le n\ \ \phi_{t_1, \ldots, t_n}(y_1, \ldots, y_{m - 1}, 0, y_{m + 1}, \ldots, y_n) = \phi_{t_1, \ldots, t_{m - 1}, t_{m + 1}, \ldots, t_n}(y_1, \ldots, y_{m - 1}, y_{m + 1}, \ldots, y_n)
	\]
\end{note}

\begin{theorem} (Критерий существования процесса с независимыми приращениями)
	Пусть на $\R$ задана вероятностная мера $Q_0$ и при всех парах $0 \le s < t$ также задана вероятностная мера $Q_{s, t}$. Тогда, существование процесса $(\xi_t)_{t \in T}$ с независимыми приращениями, для которого $Q_0$ --- распределение $\xi_0$ и $Q_{s, t}$ --- распределение $\xi_t - \xi_s$ эквивалентно выполнению следующего соотношения:
	\[
		\forall 0 \le s < u < t\ \ \phi_{s, t} = \phi_{s, u} \cdot \phi_{u, t}
	\]
	где, естественно, $\phi_{s, t}$ --- характеристическая функция меры $Q_{s, t}$.
\end{theorem}

\begin{proof}
	Покажем следствие в 2 стороны:
	\begin{itemize}
		\item[$\Ra$] Пусть $\xi$ --- соответствующий процесс с независимыми приращениями. Это означает, что
		\[
			\forall 0 \le s < u < t\ \ (\xi_u - \xi_s) \indep (\xi_t - \xi_u)
		\]
		Коль скоро это так и $\xi_t - \xi_s = \xi_t - \xi_u + (\xi_u - \xi_s)$, то получаем требуемое по свойству характеристических функций.
		
		\item[$\La$] Проверим критерий Колмогорова. Будем действовать поэтапно:
		\begin{enumerate}
			\item (Построение мер в частном случае) Пусть $\xi_0 = 0$. Тогда $Q_0 = \delta_0$ --- мера Дирака. Несложно убедиться, что $\phi_0 = 1$. В критерии требуются меры $P_{t_1, \ldots, t_n}$, которые отвечают за вероятность $(\xi_{t_1}, \ldots, \xi_{t_n})$ попасть в какое-то множество. Его аналогом может послужить $Q_{0, t_1} \otimes Q_{t_1, t_2} \otimes \ldots \otimes Q_{t_{n - 1}, t_n}$, только входное множество к $P_{t_1, \ldots, t_n}$ нужно будет преобразовать соответствующим образом для этой меры. Если $(x_1, \ldots, x_n)$ --- это точка, соответствующая множеству в аргументе меры $P_{t_1, \ldots, t_n}$, то её надо заменить на $(y_1, \ldots, y_n) = (x_1 - 0, x_2 - x_1, x_3 - x_2, \ldots, x_n - x_{n - 1})$ (отсюда, чтобы восстановить исходное множество по множеству-аргументу тензорного произведения мер, нужно пользоваться равенством $(x_1, \ldots, x_n) = (y_1, y_1 + y_2, \ldots, y_1 \plusdots y_n)$). Важно отметить, что в критерии Колмогорова не исключается ситуации наподобие $t_1 = 0$. Если это так, то $P_{0, t_2, \ldots, t_n}$ фактически является мерой $P_{t_2, \ldots, t_n}$ на пространстве $(\R^{n - 1}, \B(\R^{n - 1}))$, а для такой мы можем снова использовать конструкцию, описанную выше.
			
			\item (Изучение харфункций) Изучим поведение характеристических функций в случае взятия образа по измеримому отображению и тензорном произведении:
			\begin{lemma}
				Пусть $\mu$ --- мера на $(\R^n, \B(\R^n))$, $L \colon \R^n \to \R^n$ --- линейное отображение, $\mu' = \mu \circ L^{-1}$ --- образ $\mu$ по $L$. Тогда
				\[
					\phi_{\mu'} = \phi_\mu \circ L^*
				\]
				где $L^*$ --- сопряжённый оператор
			\end{lemma}
			
			\begin{proof}
				Распишем характеристическую функцию $\mu$ по определению:
				\begin{multline*}
					\phi_{\mu'}(y) = \int_{\R^n} e^{i(y, x)}d(\mu \circ L^{-1})(x) = \int_{\R^n} e^{i(y, x)}d\mu(L^{-1}x) =
					\\
					\int_{\R^n} e^{i(y, Lu)}d\mu(u) = \int_{\R^n} e^{i(L^*y, u)}d\mu(u) = \phi_\mu(L^*y)
				\end{multline*}
			\end{proof}
			
			\begin{lemma}
				Пусть $\mu = \mu_1 \otimes \ldots \otimes \mu_n$ --- мера на $(\R^n, \B(\R^n))$, а $\mu_k$ --- меры на $(\R, \B(\R))$. Тогда
				\[
					\phi_\mu = \bigotimes_{k = 1}^n \phi_{\mu_k}
				\]
			\end{lemma}
			
			\begin{proof}
				Снова воспользуемся определением характеристической функции:
				\begin{multline*}
					\phi_\mu(y_1, \ldots, y_n) = \int_{\R^n} e^{i(y, x)}d\mu(x) = \int_{\R^n} \prod_{k = 1}^n e^{iy_kx_k}d\mu(x_1, \ldots, x_n) = [\text{т. Фубини}] =
					\\
					\int_\R \cdots \int_\R \prod_{k = 1}^n e^{iy_kx_k} d\mu(x_1) \ldots d\mu(x_n) = \prod_{k = 1}^n \phi_{\mu_k}(y_k)
				\end{multline*}
			\end{proof}
			
			\item (Доказательство частного случая) Стало быть, характеристическая функция для $P_{t_1, \ldots, t_n}$ будет записана как
			\[
				\phi_{t_1, \ldots, t_n} = \bigotimes_{k = 1}^n (\phi_{t_{k - 1}, t_k} \circ L^*)
			\]
			Отображение $L^{-1}$ должно переносить точки из пространства исходных точек в пространство разностей. Стало быть, $L$ действует наоборот: $(y_1, \ldots, y_n) \mapsto (y_1, y_1 + y_2, \ldots, y_1 \plusdots y_n)$. Несложно проверить, что $L^* \colon (y_1, \ldots, y_n) \mapsto (y_1 \plusdots y_n, \ldots, y_{n - 1} + y_n, y_n)$. Отсюда
			\[
				\phi_{t_1, \ldots, t_n}(y) = \phi_{t_0, t_1}(y_1 \plusdots y_n) \cdot \ldots \cdot \phi_{t_{n - 2}, t_{n - 1}}(y_{n - 1} + y_n) \cdot \phi_{t_{n - 1}, t_n}(y_n)
			\]
			Пора подставить $y_m = 0$. Тогда, изменения сомножителей происходят слева-направо до $\phi_{t_m, t_{m + 1}}(y_{m + 1} \plusdots y_n)$. Заметим, что этот сомножитель и предыдущий можно <<схлопнуть>> в силу независимости:
			\[
				\phi_{t_{m - 1}, t_m}(0 + y_{m + 1} + \ldots + y_n)\phi_{t_m, t_{m + 1}}(y_{m + 1} + \ldots + y_n) = \phi_{t_{m - 1}, t_{m + 1}}(y_{m + 1}, \ldots, y_n)
			\]
			Отсюда тривиально получаем выполнение критерия.
			
			\item (Доказательство общего случая) Теперь $Q_0 \neq \delta_0$. Тогда, рассмотрим частный случай выше и к полученному процессу $\xi$ добавим независимую случайную величину $\xi_0$ с распределением $Q_0$. \textcolor{red}{Почему к заданному процессу найдётся независимая случайная величина с заданным распределением? Загадка...}
		\end{enumerate}
	\end{itemize}
\end{proof}

\begin{corollary}
	Пуассоновский процесс существует.
\end{corollary}

\begin{proof}
	Посчитаем соответствующую характеристическую функцию:
	\[
		\phi_{s, t}(y) = e^{\lambda(t - s)(e^{iy} - 1)}
	\]
	Тогда ($0 \le s < u < t$):
	\[
		\phi_{s, u}(y) \cdot \phi_{u, t}(y) = e^{\lambda(u - s)(e^{iy} - 1)} e^{\lambda(t - u)(e^{iy - 1})} = e^{\lambda(t - s)(e^{iy} - 1)} = \phi_{s, t}(y)
	\]
\end{proof}

\begin{corollary}
	Винеровский процесс существует.
\end{corollary}

\begin{proof}
	Посчитаем соответствующую характеристическую функцию:
	\[
		\phi_{s, t}(y) = e^{0 \cdot iy - \frac{(t - s)y^2}{2}} = e^{-(t - s)y^2 / 2}
	\]
	Тогда ($0 \le s < u < t$):
	\[
		\phi_{s, u}(y) \cdot \phi_{u, t}(y) = e^{-(u - s)y^2 / 2}e^{-(t - u)y^2 / 2} = e^{-(t - s)y^2 / 2}
	\]
\end{proof}

\begin{proposition}
	У винеровского процесса непрерывные трактории.
\end{proposition}

\begin{proof}
	Проверим условия теоремы Колмогорова о непрерывных траекториях. Так как $W_t - W_s \sim N(0, t - s)$, то у этой случайной величины можно явным образом посчитать все моменты. В частности:
	\[
		\E (W_t - W_s)^4 = 3(t - s)^2
	\]
	А значит все условия выполнены.
\end{proof}

\begin{definition}
	Пусть $\xi_n \sim Exp(\lambda)$ --- независимые случайные величины. Обозначим $S_n = \xi_1 \plusdots \xi_n$, $S_0 = 0$. Тогда \textit{процессом восстановления} называется процесс $\eta$, определённый следующим образом:
	\[
		\forall t \in \R_{++}\ \ \eta_t(\omega) = \sup \{n \in \N_0 \colon S_n(\omega) \le t\}
	\]
\end{definition}

\begin{theorem}
	Процесс восстановления с параметром $\lambda$ является пуассоновским процессом с параметром $\lambda$.
\end{theorem}

\begin{proof}
	Достаточно убедиться, что при $0 = t_0 < t_1 < \ldots < t_n$ и $0 = k_0 \le k_1 \le \ldots \le k_n$ вероятность
	\[
		P(\eta_{t_n} - \eta_{t_{n - 1}} = k_n - k_{n - 1} \wedge \ldots \wedge \eta_{t_1} - \eta_{t_0} = k_1 - k_0)
	\]
	распадается на $n$ соответствующих сомножителей. Ключевое наблюдение состоит в том, что это вероятность события $A$:
	\[
		S_1, \ldots, S_{k_1} \in [0; t_1] \wedge S_{k_1 + 1}, \ldots, S_{k_2} \in \rsi{t_1; t_2} \wedge \ldots \wedge S_{k_{n - 1} + 1}, \ldots, S_{k_n} \in \rsi{t_{n - 1}; t_n} \wedge S_{k_n + 1} > t_n
	\]
	Значит, если нам известно распределение вектора $(S_1, \ldots, S_n)$, то мы можем попробовать посчитать эту вероятность через многомерный интеграл (который по теореме Фубини будет разбит на повторный). Итак, заметим, что между $(S_1, \ldots, S_n)$ и $(\xi_1, \ldots, \xi_n)$ есть линейная связь через оператор $L$:
	\begin{align*}
		&{L \colon (x_1, x_2, \ldots, x_n) \mapsto (x_1, x_1 + x_2, \ldots, x_1 \plusdots x_n)}
		\\
		&{L^{-1} \colon (y_1, y_2, \ldots, y_n) \mapsto (y_1, y_2 - y_1, \ldots, y_n - y_{n - 1})}
	\end{align*}
	Отсюда $p_{S_1, \ldots, S_n}(y_1, y_2, \ldots, y_n) = p_{\xi_1, \ldots, \xi_n}(y_1, y_2 - y_1, \ldots, y_n - y_{n - 1})$. Все $\xi_k$ независимы, поэтому ($y_0 := 0$)
	\begin{multline*}
		p_{\xi_1, \ldots, \xi_n}(y_1, y_2 - y_1, \ldots, y_n - y_{n - 1}) = \prod_{k = 1}^n p_{\xi_k}(y_k - y_{k - 1}) =
		\\
		\prod_{k = 1}^n p_{\xi_1}(y_k - y_{k - 1}) = \prod_{k = 1}^n \lambda e^{-\lambda(y_k - y_{k - 1})}\chi_{\{y_k \ge y_{k - 1}\}} = \lambda^ne^{-\lambda y_n}\chi_{y_n \ge \ldots \ge y_1 \ge 0}
	\end{multline*}
	Итого:
	\[
		P(A) = \int_{U_A} \lambda^{k_n + 1}e^{-\lambda y_{k_n + 1}}\chi_{0 \le y_1 \le \ldots \le y_{k_n + 1}}d\mu(y_1, \ldots, y_{k_n + 1})
	\]
	Так как $y_{k_n + 1} > t_n$ и, следовательно, больше любой другой координаты, интегрирование по этой координате можно выделить в отдельный интеграл, что даст сомножитель $\lambda^{k_n} e^{-\lambda t_n}$. Оставшийся интеграл является объёмом области в $\R^{k_n}$, заданной неравенствами события $A$. Можно доказать, что этот объём равен
	\[
		\prod_{j = 1}^n \frac{(t_j - t_{j - 1})^{k_j - k_{j - 1}}}{(k_j - k_{j - 1})!}
	\]
	пересборкой сомножителей получим требуемое произведение вероятностей.
\end{proof}

\begin{proposition} \textcolor{red}{(не по лектору)}
	Пусть $N$ --- пуассоновский процесс. Тогда у него $P$-почти наверное кусочно-постоянные, непрерывные справа, неубывающие траектории. Более точно:
	\begin{itemize}
		\item $P(X_{t + h} - X_t = 0) = 1 - \lambda h + o(h), h \to 0$
		
		\item $P(X_{t + h} - X_t = 1) = \lambda h + o(h), h \to 0$
		
		\item $P(X_{t + h} - X_t > 1) = o(h), h \to 0$
	\end{itemize}
\end{proposition}

\begin{proof}
	Нам известно, что $X_{t + h} - X_t \sim Poiss(\lambda h)$. У этой величины следующее распределение:
	\[
		P(X_{t + h} - X_t = k) = \frac{(\lambda h)^k}{k!}e^{-\lambda h}
	\]
	Подставим $k = 0$:
	\[
		P(X_{t + h} - X_t = 0) = e^{-\lambda h} = [\text{формула Тейлора}] = 1 - \lambda h + o(h), h \to 0
	\]
	Аналогично $k = 1$:
	\[
		P(X_{t + h} - X_t = 1) = \lambda he^{-\lambda h} = \lambda h + o(h), h \to 0
	\]
	Ну и для $k > 1$:
	\begin{multline*}
		P(X_{t + h} - X_t > 1) = 1 - P(X_{t + h} - X_t \le 1) =
		\\
		1 - (1 - \lambda h + o(h)) - (\lambda h + o(h)) = o(h), h \to 0
	\end{multline*}
	Но из этого ещё не явно следует утверждение о траекториях. Заметим, что
	\[
		\forall h_1 < h_2\ \ \{\omega \in \Omega \colon X_{t + h_2}(\omega) - X_t(\omega) = 0\} \subseteq \{\omega \in \Omega \colon X_{t + h_1}(\omega) - X_t(\omega) = 0\}
	\]
	Значит, можно говорить о пределе этих множеств при $h \to 0+$ как о их пересечении. Тогда
	\[
		P(\lim_{h \to 0+} X_{t + h} - X_t = 0) = P(\lim_{h \to 0+} \{X_{t + h} - X_t = 0\}) = \lim_{h \to 0+} P(X_{t + h} - X_t = 0) = 1
	\]
	\textcolor{red}{Допридумать}
\end{proof}

\section{Гауссовские процессы}

\begin{anote}
	Прежде чем начать разговор о гауссовском процессе (который, канонично, будет вестить с точки зрения характеристических функций) стоит определить понятия, эквивалентные математическому ожиданию и дисперсии на процессах.
\end{anote}

\begin{definition} \textcolor{red}{(не по лектору)}
	Пусть $\xi$ --- случайный процесс. Тогда функция $M_\xi(t) = \E \xi_t$ называется \textit{средним случайного процесса $\xi$}.
\end{definition}

\begin{anote}
	Далее будет удобно обозначать $M_\xi(t) =: m_t$, когда понятно, о каком процессе идёт речь.
\end{anote}

\begin{definition} \textcolor{red}{(не по лектору)}
	Пусть $\xi$ --- случайный процесс. Тогда \textit{ковариационной функцией случайного процесса $\xi$} называется следующая функция:
	\[
		K(t, s) = \E(\xi_t - m_t)(\xi_s - m_s)
	\]
\end{definition}

\begin{proposition}
	Ковариационная функция всегда симметрична.
\end{proposition}

\begin{proof}
	Тривиально.
\end{proof}

\begin{proposition}
	Ковариационная функция всегда является положительно полуопределённой, то есть
	\[
		\forall \{t_k\}_{k = 1}^n \subseteq T\ \ \forall \{x_k\}_{k = 1}^n\ \ \sum_{1 \le i, j \le n} K(t_i, t_j)x_ix_j \ge 0
	\]
\end{proposition}

\begin{proof}
	Достаточно заметить, что эта сумма может быть записана как квадрат матожидания:
	\begin{multline*}
		0 \le \E\ps{\sum_{i = 1}^n x_i(\xi_{t_i} - m_{t_i})}^2 = \E\ps{\sum_{1 \le i, j \le n} x_i(\xi_{t_i} - m_{t_i})x_j(\xi_{t_j} - m_{t_j})} =
		\\
		\sum_{1 \le i, j \le n} x_ix_j\E (\xi_{t_i} - m_{t_i})(\xi_{t_j} - m_{t_j}) = \sum_{1 \le i, j \le n} K(t_i, t_j)x_ix_j
	\end{multline*}
	
\end{proof}

\begin{reminder}
	\textit{Гауссовской (Нормальной) случайной величиной} $\xi$ называется либо константа, либо случайная величина с плотностью распределения следующего вида ($\sigma > 0$, $a \in \R$):
	\[
		p_\xi(x) = \frac{1}{\sqrt{2\pi}}e^{-(x - a)^2 / (2\sigma)}
	\]
	Известно, что $\E \xi = a$, $D\xi = \sigma^2$. Обозначается как $\xi \sim N(a, \sigma^2)$.
\end{reminder}

\begin{reminder}
	\textit{Гауссовским случайным вектором} $\xi = (\xi_1, \ldots, \xi_n)$ в $\R^n$ называется такой случайный вектор, что все линейные комбинации $\sum_{k = 1}^n c_k\xi_k$ являются гауссовскими случайными величинами
\end{reminder}

\begin{exercise}
	Привести пример двух гауссовских случайных величин $\xi_1, \xi_2$ таких, что их случайный вектор $\xi = (\xi_1, \xi_2)$ не гауссовский.
\end{exercise}

\begin{definition}
	\textit{Гауссовским случайным процессом} $\xi$ называется случайный процесс, для которого все конечномерные распределения являются гауссовскими
\end{definition}

\begin{proposition}
	Процесс является гауссовским тогда и только тогда, когда все линейные комбинации $\sum_{k = 1}^n c_k\xi_{t_k}$. являются гауссовскими случайными величинами.
\end{proposition}
