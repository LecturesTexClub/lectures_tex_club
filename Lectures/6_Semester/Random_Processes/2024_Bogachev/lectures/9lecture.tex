\begin{definition}
	Пусть $\xi$ --- процесс, обладающий переходной функцией $P(s, x, t, B)$. Если она выразима как функция $P'(t - s, x, B)$, то процесс называется \textit{однородным}. Тогда можно говорить, что задана функция $P(x, t, B)$, интерпретируемая как вероятность попасть в множество $B$ в момент времени $t$ при нахождении процесса $\xi$ в точке $x$ в момент времени $0$.
\end{definition}

\section{Марковские цепи}

\begin{definition}
	\textit{Однородной цепью Маркова} называется однородный марковский процесс, обладающий дискретным временем $T = \N_0$ и не более чем счётным фазовым пространством $E = \{x_j\}_{j = 1}^{\{m, \infty\}}$
\end{definition}

\begin{note}
	Далее будет рассматриваться однородная цепь Маркова с счётным фазовым пространством.
\end{note}

\begin{note}
	Уже из того, что было дано в определении, переходная функция цепи $\xi$ будет определяться счётным числом значений $p_{i, j} \ge 0$ --- вероятность перехода из $x_i$ в $x_j$ за 1 шаг. Тогда понятно, что
	\[
		\forall i \in \N_0\ \ \sum_{j = 1}^\infty p_{i, j} = 1
	\]
\end{note}

\begin{note}
	Однородная цепь Маркова является очень интересным объектом. Если мы знаем распределение цепи $\pi_0$ в момент времени $0$ (это распределение на $(E, \cE)$), то можем найти $\pi_1$ и так далее. Действительно, вероятность попадания процесса в $x_j$ в момент времени $1$ может быть записана как
	\[
		\sum_{i = 1}^\infty \pi_0(x_i)p_{i, j}
	\]
	Значит, если сопоставить $\pi_n$ его координатную строку $(\pi_n(x_1), \pi_n(x_2), \ldots)$, а за $P$ положить двумерную бесконечную матрицу (в счётном случае) $P = (p_{i, j})_{i, j \ge 1}$, то получим связь
	\[
		\pi_1 = \pi_0P
	\]
	А значит, $\pi_n = \pi_{n - 1}P = \ldots = \pi_0P^n$
\end{note}

\begin{note}
	Это всё здорово, но как и всегда есть один важный вопрос --- а существуют ли вообще однородные цепи Маркова? Ответ конечно же положителен, его даёт следующая теорема.
\end{note}

\begin{note}
	Далее, матрицей перехода называется матрица с неотрицательными элементами, причём сумма в любой строке равна единице.
\end{note}

\begin{theorem}
	Пусть $P = (p_{i, j})_{i, j \ge 1}$ --- матрица перехода, $\pi_0$ --- начальное распределение на $(E, \cE)$. Тогда, существует однородная цепь Маркова с фазовым пространством $E$, для которой $\pi_0$ является распределением $\xi_0$ и $p_{i, j} = P(\xi_{n + 1} = x_j | \xi_n = x_i)$.
\end{theorem}

\begin{proof}
	Хоть теорема Колмогорова о существовании процесса была для случая $E = \R$, мы можем свести общую ситуцию к такой же. В силу счётности $E$, каждому элементу однозначно сопоставлен его индекс. Будем считать, что $x_i = i$. Необходимо предъявить согласованные меры на $\R^n$. Так как они будут сконцетрированы на $\{1, \ldots, m\}^n$, то достаточно предъявить меры на этом подпространстве. Положим $P_0 = \pi_0$, а остальные конечные распределения задаются так:
	\[
		P_{1, \ldots, n}(i_1, \ldots, i_n) = P_0(i_1) \cdot p_{i_1, i_2} \cdot \ldots \cdot p_{i_{n - 1}, i_n}
	\]
	Меры на остальных подмножествах $T = \N_0$ получаются проекциями уже имеющихся мер $P_{1, \ldots, n}$. Например:
	\[
		P_{2, 3}(i, j) = \sum_{k = 1}^m P_{1, 2, 3}(k, i, j) = \sum_{k = 1}^m \pi_0(k)p_{k, i}p_{i, j}
	\]
	Также очевидно, что проекция $P_{1, \ldots, n + 1}$ на $\{1, \ldots, m\}^n$ даст $P_{1, \ldots, n}$, поскольку $\sum_{j = 1}^m p_{i, j} = 1$. Итак, теорема Колмогорова даёт существование согласованного с нашими мерами процесса $\xi$. При этом, мы ещё не проверили соблюдение марковости и равенства для $p_{i, j}$. Для них достаточно проверить такие равенства соответственно:
	\begin{align*}
		&{\forall t_1 < t_2 < t_3\ \ P(\xi_{t_1} = i \wedge \xi_{t_3} = j | \xi_{t_2} = l) = P(\xi_{t_1} = i | \xi_{t_2} = l) \cdot P(\xi_{t_3} = j | \xi_{t_2} = l)}
		\\
		&{\forall n \in \N\ \ P(\xi_{n - 1} = i \wedge \xi_n = j) = p_{i, j}P(\xi_{n - 1} = i)}
	\end{align*}
	Вторая формула оказывается верной по определению:
	\begin{multline*}
		P(\xi_{n - 1} = i \wedge \xi_n = j) = P_{(n - 1), n}(i, j) =
		\\
		\sum_{k_1, \ldots, k_{n - 2}} P_{1, \ldots, n}(k_1, \ldots, k_{n - 2}, i, j) = \sum_{k_1, \ldots, k_{n - 2} = 1}^m \pi_0(k_1)p_{k_1, k_2} \cdot \ldots \cdot p_{k_{n - 2}, i}p_{i, j} =
		\\
		\ps{\sum_{k_1, \ldots, k_{n - 2}}^m \pi_0(k_1)p_{k_1, k_2} \cdot \ldots \cdot p_{k_{n - 2}, i}}p_{i, j} = P(\xi_{n - 1} = i)p_{i, j}
	\end{multline*}
	Из верности этого соотношения также получается более общая формула:
	\[
		\forall m < n\ \ P(\xi_m = i | \xi_n = j) = p_{i, j}^{(n - m)},\ p_{i, j}^{(n - m)} = (P^{n - m})_{i, j}
	\]
	Для первой, по формуле условной вероятности переходим к следующему:
	\[
		\forall t_1 < t_2 < t_3\ \ P(\xi_{t_1} = i \wedge \xi_{t_3} = j \wedge \xi_{t_2} = l)P(\xi_{t_2} = l) = P(\xi_{t_1} = i \wedge \xi_{t_2} = l) \cdot P(\xi_{t_3} = j \wedge \xi_{t_2} = l)
	\]
	Величины справа можно посчитать так:
	\[
		P(\xi_{t_1} = i \wedge \xi_{t_2} = l) = P(\xi_{t_1} = i | \xi_{t_2} = l)P(\xi_{t_2} = l) = p_{i, l}^{(t_2 - t_1)}P(\xi_{t_2} = l)
	\]
	Если преобразовать крайнюю правую величину подобным образом, то придём к такой формулировке проверяемого равенства:
	\[
		\forall t_1 < t_2 < t_3\ \ P(\xi_{t_1} = i \wedge \xi_{t_3} = j \wedge \xi_{t_2} = l) = P(\xi_{t_1} = i \wedge \xi_{t_2} = l)p_{l, j}^{(t_3 - t_2)}
	\]
	Будем доказывать индукцией по $t_3 - t_2$.
	\begin{itemize}
		\item База $t_3 - t_2 = 1$. При подстановке получим
		\[
			\forall t_1 < t_2\ \ P(\xi_{t_1} = i \wedge \xi_{t_2} = l \wedge \xi_{t_2 + 1} = j) = P(\xi_{t_1} = i \wedge \xi_{t_2} = l)p_{l, j}
		\]
		Это вытекает из определения $P$, как и в случае второй формулы.
		
		\item Переход $t_3 - t_2 > 1$. Сведём левую вероятность к предположению индукции:
		\begin{multline*}
			P(\xi_{t_1} = i \wedge \xi_{t_2} = l \wedge \xi_{t_3} = j) = \sum_{k = 1}^m P(\xi_{t_1} = i \wedge \xi_{t_2} = l \wedge \xi_{t_3 - 1} = k)p_{k, j} =
			\\
			\sum_{k = 1}^m P(\xi_{t_1} = i \wedge \xi_{t_2} = l)p_{l, k}^{(t_3 - t_2 - 1)}p_{k, j} = P(\xi_{t_1} = i \wedge \xi_{t_2} = l) \sum_{k = 1}^m p_{l, k}^{(t_3 - t_2 - 1)}p_{k, j} =
			\\
			P(\xi_{t_1} = i \wedge \xi_{t_2} = l)p_{l, j}^{(t_3 - t_2)}
		\end{multline*}
	\end{itemize}
\end{proof}

\begin{definition}
	Пусть $P$ --- матрица перехода. Тогда распределение $\pi$ на $(E, \cE)$ называется \textit{стационарным (инвариантным)}, если
	\[
		\pi P = \pi
	\]
\end{definition}

\begin{theorem}
	Если $E$ --- конечное пространство и $P$ ---матрица перехода, то существует хотя бы одна стационарная мера на нём.
\end{theorem}

\begin{proof}
	Обозначим за $\cP$ --- множество всех мер на $(E, \cE)$. Тогда $\cP$ --- конечномерный симплекс. Отображение $\phi \colon \pi \mapsto \pi P$ является непрерывным на этом симплексе, а потому по теореме Брауэра должна существовать неподвижная точка.
\end{proof}

\begin{theorem} (эргодическая)
	Пусть $E = \{x_j\}_{j = 1}^m$ и при некотором $n_1 \in \N$ все элементы некоторой матрицы $P$ положительны. Тогда, существует и единственна инвариантная вероятностная мера $\mu$ на $(E, \cE)$. Более того\begin{itemize}
		\item $\forall i \le m\ \mu(x_j) > 0$
		
		\item Для всякой начальной меры $\pi_0$ на $(E, \cE)$, последовательность мер $\pi_n = \pi_0 P^n$ сходится к $\mu$.
	\end{itemize}
\end{theorem}

\begin{note}
	В конечномерных пространствах все нормы эквивалентны, поэтому неважно, о какой сходимости говорить.
\end{note}

\begin{proof}
	Так как $E$ конечно, инвариантная вероятностная мера $\mu$ существует.
	\begin{itemize}
		\item (Сходимость) В силу аналогичности, пусть $n_1 = 1$. Обозначим $M = (m_{i, j})_{i, j \ge 1}$ --- матрица, все строки которой совпадают со строкой $\mu$. Несложно убедиться, что для любой вероятностной меры $\pi$ на $(E, \cE)$ тогда выполнено равенство
		\[
			\pi M = \mu
		\]
		Так как $p_{i, j} > 0$, найдётся $\delta \in (0; 1)$ что $P \ge \delta M$ (сравнение поэлементное). Обозначим $\lambda = 1 - \delta$ и заметим, что $P$ представимо в виде линейной комбинации $M$ с некоторой матрицей $Q$:
		\[
			P = (1 - \lambda) M + \lambda Q
		\]
		Так как $P - \delta M = \lambda Q \ge 0$, то $q_{i, j} \ge 0$ и $\sum_{j = 1}^m q_{i, j} = 1$. Заметим следующие алгебраические свойства:
		\begin{enumerate}
			\item $M^2 = M$
			
			\item $MP = PM = M$
			
			\item $MQ = QM = M$
		\end{enumerate}
		По индукции покажем, что степень $P^n$ может быть записана как
		\[
			P^n = (1 - \lambda^n)M + \lambda^nQ^n
		\]
		\begin{itemize}
			\item База $n = 1$: тривиально
			
			\item Переход $n > 1$:
			\begin{multline*}
				P^n = ((1 - \lambda) M + \lambda Q)P^{n - 1} =
				\\
				((1 - \lambda)M + \lambda Q)((1 - \lambda^{n - 1})M + \lambda^{n - 1}Q^{n - 1}) =
				\\
				(1 - \lambda^{n - 1})M + ((1 - \lambda)M + \lambda Q)\lambda^{n - 1}Q^{n - 1} =
				\\
				(1 - \lambda^{n - 1} + \lambda^{n - 1} - \lambda^n)M + \lambda^nQ^n = (1 - \lambda^n)M + \lambda^nQ^n
			\end{multline*}
		\end{itemize}
		Это равенство позволяет показать сходимость $\pi_n = \pi_0 P^n$ к $\mu$. Рассмотрим соответствующую разность:
		\[
			\pi_0 P^n - \mu = \pi_0 P^n - \mu P^n = (\pi_0 - \mu)P^n = (\pi_0 - \mu)((1 - \lambda^n)M + \lambda^nQ^n) = \lambda^n(\pi_0 - \mu)Q^n
		\]
		$\|(\pi_0 - \mu)Q^n\| \le \|\pi_0 - \mu\| \cdot \|Q\|^n$. Если рассмотреть норму на строках, равную сумме модулей координат, то с учётом порождённой нормы матрицы получится оценка $\le 2$.
		
		\item (Единственность) Пусть $\nu$ --- ещё одна инвариантная вероятностная мера. Тогда 
		\[
			\nu = \nu P^n = \lim_{n \to \infty} \nu P^n = \mu
		\]
		
		\item (Положительность вероятности) Так как $\mu$ это распределение, то $\forall i \le m\ \mu(x_i) \ge 0$ и $\exists j \le m \colon \mu(x_j) > 0$. Поэтому, раз $\mu = \mu P^{n_1}$, то $\forall i \le m\ \mu(x_i) = (\mu P^{n_1})(x_i) > 0$
	\end{itemize}
\end{proof}

\begin{note}
	Условие положительности $P$ хоть при какой-то степени $n_1 \in \N$ существенно. Если всякая степень $P^n$ имеет нулевой элемент, то для некоторых элементов $x_{i_0}$, $x_{j_0}$ найдётся бесконечная последовательность $\{n_k\}_{k = 1}^\infty$ такая, что матрица $P^{n_k}$ имеет нулевой элемент с индексами $i_0, j_0$. Тогда, для меры $\pi$ следующего вида
	\[
		\pi(x_i) = \System{
			&{0, i \neq i_0}
			\\
			&{1, i = i_0}
		}
	\]
	получится $(\pi P^{n_k})(x_{j_0}) = 0$, поэтому предел мер $\mu$ не сможет быть положителен для всех $x_j$.
\end{note}