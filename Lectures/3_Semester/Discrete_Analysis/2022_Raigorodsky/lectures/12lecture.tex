\begin{theorem}
	Пусть $p = p(n) = c / n$. Имеют место следующие утверждения:
	\begin{enumerate}
		\item Если $c < 1$, то существует такое $\beta > 0$, что асимптотически почти наверное число вершин в каждой связной компоненте случайного графа не превосходит $\beta \ln n$
		
		\item (без доказательства) Если $c > 1$, то существует такое $\beta > 0$ и $\gamma \in (0; 1)$, что асимптотически почти наверное в случайном графе есть ровно одна компонента с $\ge \gamma n$ вершин (так называемая \textit{гигантская компонента}), а все остальные компоненты имеют $\le \beta \ln n$ вершин
	\end{enumerate}
\end{theorem}

\begin{proof}
	Доказательство первого пункта теоремы опирается на рассмотрение <<игры-жизни>> на графе, некоего \textit{случайного процесса жизни}:
	\begin{enumerate}
		\item Время дискретно: $t \in [0; +\infty)$
		
		\item В каждый момент времени вершины разделяются на 3 класса: нейтральные, живые и мёртвые. Переход возможен лишь из левого состояния в правое соответственно
		
		\item В графе фиксируется вершина $v_0 \in V$, которая является выбранной по умолчанию вершиной и изначально принадлежит к классу живых
		
		\item Каждую итерацию происходит несколько действий:
		\begin{enumerate}
			\item Выбирается одна вершина из живых
			
			\item Все нейтральные вершины, связанные с ней, торжественно объявляются живыми
			
			\item После действий выше, выбранная вершина торжественно погибает
		\end{enumerate}
	\end{enumerate}
	В силу конечности графа, всегда наступает момент, что у нас не остаётся живых вершин. Более того, должно быть понятно, что по номеру итерации, когда у нас впервые стало 0 живых вершин, мы можем дать какую-то оценку на размер компоненты, в которой находится $v_0$. В этом и состоит вся идея. Введём следующие величины:
	\begin{itemize}
		\item $Y_t$ --- количество живых вершин на $t$-й итерации
		
		\item $N_t$ --- количество нейтральных вершин на $t$-й итерации
		
		\item $Z_t$ --- число потомков (нейтральных соседей) выбранной на $t$-й итерации живой вершины
	\end{itemize}
	Тогда, у нас имеются по умолчанию следующие соотношения:
	\begin{itemize}
		\item $Y_0 = 1$
		
		\item $Y_t = Y_{t - 1} + Z_t - 1$
		
		\item $Z_t$ понимается как случайная величина с распределением $Binom(N_t, p)$. На всякий случай напоминание:
		\[
			P(Z_t = k) = C_{N_{t - 1}}^k p^k (1 - p)^{N_{t - 1} - k}
		\]
	\end{itemize}
	\textcolor{red}{Почему это так работает? Узнаю завтра на консультации}
	\begin{lemma}
		Верно, что $Y_t \sim Binom(n - 1, 1 - (1 - p)^t) + 1 - t$
	\end{lemma}

	\begin{proof}
		Для начала можно заметить, что $N_t = n - t - Y_t$. Тогда доказать распределение для $Y_t$ равносильно тому, что доказать распределение числа нейтральных вершин:
		\[
			N_t \sim Binom(n - 1, (1 - p)^t)
		\]
		Действительно, если бы это распределение было верным, то есть равенство $Y_t = (n - 1) - N_t + 1 - t$, где часть с $N_t$ является по сути числом неудач в испытаниях Бернулли, если успех учитывать в число $N_t$. Это распределение для $N_t$ мы докажем по индукции:
		\begin{itemize}
			\item База $t = 0$: $N_0 \sim Binom(n - 1, 1)$ --- это очевидная правда
			
			\item Переход $t > 0$: для него мы воспользуемся рекурсивной формулой на число живых вершин:
			\[
				N_t = n - t - Y_t = n - t - Y_{t - 1} - Z_t + 1 = \underbrace{n - (t - 1) - Y_{t - 1}}_{N_{t - 1}} - Z_t
			\]
			Внимательно посмотрим на получившийся результат. $Z_t$ --- это как раз число выбранных из $N_{t - 1}$, то есть число успехов в $N_{t - 1}$ испытании (учитывая распределение). Несложно понять, что тогда $N_t$ --- это число провалов в том же испытании, то есть $N_t \sim Binom(N_{t - 1}, 1 - p)$. Теперь поймём, что $N_t$ происходит независимо от $N_{t - 1} \sim Binom(n - 1, (1 - p)^{t - 1})$, что позволяет выразить распределение $N_t$ как просто число успехов на $n - 1$ испытании с вероятностью $(1 - p)^t$, то есть $Binom(n - 1, (1 - p)^t)$.
		\end{itemize}
		\textcolor{red}{Я отказываюсь писать то, что я не понимаю. Возможно, будет дописано после консультации}
	\end{proof}
\end{proof}

\textcolor{red}{Здесь должен быть изоморфизм графов}