
\subsection{Теорема о фазовом переходе}

\begin{theorem}(О фазовом переходе)
    Пусть $p = p(n) = \frac{c}{n}, c >0.$ Имеют место следующие утверждения:

    \begin{enumerate}
        \item Если $c < 1$, то \exists $\beta > 0$: а.п.н. число вершин в каждой компоненте случайного графа не превосходит $\beta \ln{n}$
        \item(б/д) Если $c > 1$, то \exists $\beta > 0$ \exists $\gamma \in (0,1)$: а.п.н. ровно $1$ компонента имеет хотя бы $\gamma n $ вершин, а все остальные имеют не больше, чем $\beta \ln{n}$ вершин.
    \end{enumerate}
    
\end{theorem}

\begin{proof}
Доказательство первого пункта теоремы опирается на рассмотрение «игры-жизни» на графе, некоего случайного процесса жизни:

\begin{itemize}
    \item  Время дискретно: $t \in [0, +\infty)$
    \item В каждый момент времени вершины разделяются на $3$ класса: нейтральные, живые и мёртвые. Переход возможен лишь из левого состояния в правое соответственно.
    \item В графе фиксируется вершина $v_0 \in V$ , которая является выбранной по умолчанию вершиной и изначально принадлежит к классу живых
    \item Каждую итерацию происходит несколько действий:
    \begin{enumerate}
        \item Выбирается одна вершина из живых
        \item Все нейтральные вершины, связанные с ней, торжественно объявляются живыми
        \item После действий выше, выбранная вершина торжественно погибает
    \end{enumerate}

\end{itemize}

Введём случайные величины:
    \begin{itemize}
        \item $Y_t$ - число живых вершин на итерации $t$, $Y_0 = 1$.
        \item $N_t$ - количество нейтральных вершин на итерации $t$, $N_0 = n -1$.
        \item $Z_t$ -  число потомков (нейтральных соседей) выбранной на $t$-й итерации живой вер- шины)
    \end{itemize}
Можем записать следующие соотношения:

\begin{itemize}
    \item $Y_t = n - N_t-t$
    \item $N_t = n - Y_t - t$
    \item $Y_t = Y_{t-1}+Z_t-1$
    \item $Z_{t+1}$ понимается как случайная величина с распределением $Binom(N_t, p)$:\\
    $Z_{t+1} \thicksim Binom(N_t,p)$, то есть $P(Z_t = k) = C_{N_{t-1}}^k p^k (1-p)^{N_{t-1} - k}$
\end{itemize}

\begin{proposition}
    $Y_t \thicksim Binom(n-1, 1-(1-p)^t) + 1 -t$
\end{proposition}

\begin{proof}
Переформулируем утверждение в терминах $N_t$:
    $N_t = n - Y_t - t = n-1-Binom(n-1, 1-(1-p)^t)$. \\Внимательно посмотрим на получившийся результат. $Z_t$ — это как раз число вы- бранных из $N_{t-1}$, то есть число успехов в $N_{t-1}$ испытании (учитывая распределение). Несложно понять, что тогда $N_t$ — это число провалов в том же испытании, то есть $N_t \thicksim$ $Binom(N_{t-1}, 1 - p)$. Теперь поймём, что $N_t$ происходит независимо от $N_{t-1} \thicksim Binom(n-1, (1-p)^{t-1})$, что позволяет выразить распределение $N_t$ как просто число успехов на $n-1$ испытании с вероятностью $(1-p)^t$, то есть $Binom(n-1, (1-p)^{t})$.
    Поэтому достаточно показать, что $N_t \thicksim Binom(n-1, (p-1)^t).$ Докажем это по индукции: \\
    \begin{itemize}
        \item База при $t=0$: $N_0 \thicksim Binom(n-1, (1-p)^0)$ - верно.
        \item Переход:\\
        $N_t = n-Y_t-t=n-t-Y_{t-1}-Z_t+1 = n - Y_{t-1}-(t-1)-Z_t=N_{t-1} - Binom(N_{t-1}, p) \thicksim Binom(N_{t-1},1-p).$ При этом $N_{t-1} \thicksim Binom(n-1, (1-p)^{t-1}).$ 
        По сути, $N_{t-1}$ это число успехов на $n-1$ испытании с вероятностью $(1-p)^{t-1}$, но если на множестве этих успехов еще раз независимо бросить монетку с вероятностью $1-p$, то это будет то же самое, как если бы мы бросили монетку $n-1$ раз с вероятностью $(1-p)^t$.
        Поэтому $N_t = Binom(n-1, (1-p)^t)$.
    \end{itemize}
\end{proof}


\begin{multline*}
P(\text{размер компоненты, содержащий данную вершину больше либо равен t})\leq \\ \leq P(Y_t > 0) = 
P(Binom(n-1, 1-(1-p)^{t}) \geq t)\leq \\\leq P(Binom(n, pt) \geq t). 
\end{multline*}
Последнее неравенство верно, так как $1-(1-p)^t \geq pt$ по неравенству Бернулли.

Теперь мы хотим как-то оценить последнюю вероятность. Для этого нам поможет следующая теорема:

\begin{theorem} (Неравенство большого уклонения)
	Пусть $\xi_1, \ldots, \xi_n$ --- одинаковые независимые случайные величины, $P\{\xi_i = 1\} = \frac{1}{2} = P\{\xi_i = -1\}$. Тогда утверждается, что
	\[
		\forall a > 0 \quad P(\xi_1 + \ldots + \xi_n \ge a) \le e^{-\frac{a^2}{2n}}
	\]
\end{theorem}

\begin{proof}
	Пусть $\lambda > 0$. Тогда имеют место следующие равенства:
	\[
		P(\xi_1 + \ldots + \xi_n \ge a) = P(\lambda(\xi_1 + \ldots + \xi_n) \ge \lambda a) = P(e^{\lambda (\xi_1 + \ldots + \xi_n)} \ge e^{\lambda a})
	\]
	По неравенству Маркова
	\begin{multline*}
		P(e^{\lambda (\xi_1 + \ldots + \xi_n)} \ge e^{\lambda a}) \le e^{-\lambda a} \cdot E(e^{\lambda(\xi_1 + \ldots + \xi_n)}) = e^{-\lambda a} \prod_{i = 1}^n E(e^{\lambda \xi_i}) = e^{-\lambda a} (\frac{e^\lambda + e^{-\lambda}}{2})^n =
		\\
		e^{-\lambda a} (\sum_{l = 0}^\infty \frac{\lambda^{2l}}{(2l)!})^n \le e^{-\lambda a} (\sum_{l = 0}^\infty \frac{\lambda^{2l}}{l! \cdot 2^l})^n = e^{{(-\lambda a + \frac{\lambda^2}{2}n)}}
	\end{multline*}
	В показателе экспоненты стоит квадратный трехчлен с положительным старшим коэффициентом, поэтому лучшая оценка будет при $\lambda = \frac{a}{n}$. Если подставить, то
	\[
		P(\xi_1 + \ldots + \xi_n \ge a) \le \exp({-\frac{a^2}{2n}})
	\]
\end{proof}

Оценим с помощью этого неравенства теперь нашу вероятность:

\[
Binom(n, pt) = \chi_1 + \dots + \chi_n, \chi_i = \begin{cases}
    1, \text{с вероятностью }pt\\0,\text{с вероятностью } 1-pt
\end{cases}
\]

\begin{multline*}
P(\chi_1 + \dots + \chi_n \geq t) =\\
=P(\chi_1 + \dots + \chi_n - E(\chi_1 + \dots + \chi_n) \geq t - E(\chi_1 + \dots + \chi_n)) =\\
\\=P(\chi_1 + \dots + \chi_n-ct\geq t-ct)
\end{multline*}

В явном виде неравенство большого уклонения применить здесь не получается, так как оно у нас доказано для симметричного блуждания, то есть когда  $P\{\xi_i = 1\} = \frac{1}{2} = P\{\xi_i = -1\}$.
Вместо этого мы сошлёмся на классическую теорему из теории вероятностей:

\begin{theorem} (Центральная предельная теорема)

Пусть $\xi_1, \dots \xi_n$ - независимые одинаково распределённые случайные величины. $E\xi_i = a, D\xi_i = \sigma^2$. Тогда 
\[
P(\frac{\xi_1+\dots+\xi_n-na}{\sigma\sqrt{n}} \geq x
) \thicksim_{n\to \infty} \int_x^{+\infty} e^{-\frac{t^2}{2}}dt\]
   
\end{theorem}

\[
D(\chi_1+\dots+\chi_n) = nD(\chi_1) = n(pt-(pt)^2)= npt(1-pt) = ct(1-\frac{ct}{n}) \thicksim ct
\]

\begin{multline*}
P(\chi_1 + \dots + \chi_n-ct\geq t-ct) =\\
=P(\frac{\chi_1+\dots+\chi_n-ct}{\sqrt{ct(1-\frac{ct}{n}})} \geq \frac{t-ct}{\sqrt{ct(1-\frac{ct}{n}})}) \thicksim\\
\\\thicksim \int_{\frac{t-ct}{\sqrt{ct(1-\frac{ct}{n}})}}^{\infty} e^{\frac{-u^2}{2}}du
\end{multline*}

Интеграл от быстро убывающей функции это примерно её значение на конце:
\[
\int_{\frac{t-ct}{\sqrt{ct(1-\frac{ct}{n}})}}^{\infty} e^{\frac{-u^2}{2}}du
   \approx e^{-\frac{1}{2}({\frac{t-ct}{\sqrt{ct}}})^2}
   \thicksim e^{-\frac{1}{2}(\gamma \sqrt{t})^2}
\] 
\end{proof}

Возникает вопрос: как именно устроены компоненты связности, на которые распадается граф? Ответ на него дают следующие утверждения:

\begin{proposition}

\begin{itemize}
        \item Если $pn^2 \to 0$, то а.п.н. в графе нет рёбер, то есть все компоненты - изолированные вершины, то есть $\alpha(G) = n$, a $\chi(G) = 1$.
    \item $pn^2 \to \infty$ то а.п.н. ребра есть.
    \item $pn \to 0$, то а.п.н все компоненты графа являются дереьвями, т.е. а.п.н нет циклов
    \end{itemize}

    
\end{proposition}

\begin{proof}
Докажем третий пункт:

\[
E(\text{числа циклов})\sum_{r = 3}^n C_n^r \frac{(r-1)!}{2} p^r < \sum_{r = 3}^n (np)^r < \sum_{r =3}^{\infty} (np)^r = \frac{(np)^3}{1-np} \to 0
\]
\end{proof}


\subsection{Теоремы Боллобаша}

\begin{theorem} (80-е годы прошлого века, Бела Боллобаш)
	Пусть $p = n^{-\alpha}$, $\alpha \in (5 / 6; 1)$. Тогда существует функция $u(n, \alpha)$ такое, что для $G(n, p)$ асимптотически почти наверное $\chi(G) \in \{u, u + 1, u + 2, u + 3\}$.
\end{theorem}

\begin{note}
	Сейчас теорема улучшена до ограничений $\alpha \in (1 / 2; 1)$ и результата $\chi(G) \in \{u, u + 1\}$.
\end{note}

\begin{theorem} (80-е годы прошлого века, Бела Боллобаш)
	Пусть $p = 1 / 2$. Тогда существует функция $\phi(n) = o(n / \ln n)$ такая, что асимтотически почти наверное имеет место неравенство:
	\[
		\frac{n}{2\log_2 n} - \phi(n) \le \chi(G) \le \frac{n}{2\log_2 n} + \phi(n)
	\]
\end{theorem}

