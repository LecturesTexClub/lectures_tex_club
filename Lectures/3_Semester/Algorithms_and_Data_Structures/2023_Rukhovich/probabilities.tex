\section{Вероятностные алгоритмы}
\textbf{Определение.} Алгоритм типа Лас-Вегас --- алгоритм, который всегда выдаёт правильный ответ, время работы не гарантировано.

\textbf{Определение.} Алгоритм типа Монте-Карло --- алгоритм, который всегда работает быстро, корректность не гарантирована.

\subsection{Быстрая сортировка}
Оценим количество пар, которые сравнивались в процессе алгоритма.
Не умаляя общности, мы сортируем перестановку чисел от $1$ до $n$.
Найдём математическое ожидание: пусть $I_{i,j}$ --- индикатор того, что числа $i$ и $j$ сравнивались.
Тогда время работы алгоритма --- математическое ожидание $\sum_{i, j} I_{i,j}$, или сумма вероятностей того, что $i$ и $j$ сравнивались.
А эта вероятность равна тому, что когда мы в первый раз выбрали pivot на отрезке $[i, j]$, мы попали в $i$ или $j$.
То есть математическое ожидание равно
\[
    \sum_{i < j} \frac{2}{j - i + 1} = \sum_{l=2}^{n} \frac{2}{l} (n - l + 1) \le 2n \sum_{l=2}^{n} \frac{1}{l} \le 2 n \log(n) = O(n \log(n)).
\]
С какой вероятностью алгоритм всё равно будет долго работать?
Пусть $X$ --- количество сравнений.
Применяя неравенство Маркова, получаем
\[
    P(X \ge \alpha n \log(n)) \le \frac{2}{\alpha}.
\]
Делание выводов остаётся в качестве упражнения.

\subsection{Быстрая $k$-ая порядковая статистика}
Сделаем всё то же самое, вновь хотим найти вероятность того, что элементы $i$ и $j$ сравнивались.
Если $k$-ый элемент лежит на отрезке $[i, j]$, то это будет вероятность того, что pivot попал в $i$ или $j$.
Если же он вне отрезка (пусть $k < i < j$), то это вероятность того, что при первом попадании pivot-а в отрезок $[k, j]$ он попал в $i$ или $j$.
Следовательно, математическое ожидание --- это
\[
    \sum_{i \le k \le j} \frac{2}{i - j + 1} + \sum_{k < i < j} \frac{2}{j - k + 1} + \sum_{i < j < k} \frac{2}{k - i + 1}.
\]
Дальше техника.

\subsection{Random Tree Game Eval}
Пусть у нас двоичное дерево высоты $2n$. Изначально в корне стоит фишка, два игрока её двигают в потомка по выбору.
В каждом листе написан номер игрока, который выигрывает при входе в него.
Кто выиграет при оптимальной игре?

Можно насчитать динамику за $4^n$, и это нельзя улучшить, если нам нужно сначала считать дерево.
Но что, если у нас есть оракул, который может по листу сказать, выигрышая ли вершина?
Тогда можно идти в случайного потомка, и так, пока не найдём выигрышную стратегию.
Пусть $T_W(n)$ --- математическое ожидание ходов на $n$-ом уровне при победе игрока, который ходит сейчас, $T_L(n)$ --- при поражении.
Тогда
\[
    T_W(2n) \le \frac{1}{2} T_L(2n-1) + \frac{1}{2} (T_L(2n - 1) + T_W(2n-1)) + 1.
\]
Мы попадём в проигрышную ситуацию для противника либо с первого раза (первое слагаемое), либо в первый раз не повезёт, и мы пойдём в другое поддерево (второе слагаемое).
\[
    T_L(2n) \le 2T_W(2n-1) + 1 \le 2T_L(2n-2) + T_W(2n-2) + 3.
\]
Здесь всё проще: пошли в оба поддерева, и в обоих не повезло.
Второй переход получили, раскрыв $T_W$ по первому неравенству.

Теперь улучшим оценку на $T_W$:
\[
    T_W(2n) \le T_L(2n-1) + \frac{1}{2} T_W(2n-1) + 1 \le 
\]
\[
    \le 2T_W(2n-2) + 1 + \frac{1}{2} (T_L(2n-2) + \frac{1}{2} T_W(2n-1) + 1) + 1 =
\]
\[
    = \frac{9}{4} T_W(2n-2) + \frac{1}{2} T_L(2n-2) + \frac{5}{2}.
\]
Все переходы получены чистой арифметикой.
Главная идея --- выразить $2n$-ый член через $(2n-2)$-ой.

\textbf{Утверждение.} $T_W(2n), T_L(2n) \le C \cdot 3^n - D$. Доказывается через первый семестр.

\subsection{Минимальный разрез в невзвешенном графе}
Выберем случайное ребро.
Сожмём две его вершины в одну.
Будем так делать, пока не останется две вершины: количество рёбер между ними --- минимальный разрез.
С какой вероятностью мы промахнёмся? Пусть $ans$ --- минимальный разрез.
Мы ошиблись, если стянули ребро из минимального разреза, то есть с вероятностью $\frac{ans}{E}$.
Тогда
\[
    2E = \sum_{v \in V} \deg(v) \ge ans \cdot V \iff \frac{ans}{E} \le \frac{2}{V}.
\]
Первое неравенство из того, что мы можем взять разрез из одной вершины и $\deg(v)$ рёбер --- его весом как раз будет $\deg(v)$, так как граф невзвешен.
То есть слева просуммировали $V$ каких-то разрезов, а справа --- $V$ минимальных.
Тогда вероятность успеха --- вероятность того, что мы ни разу не взяли ребро из минимального разреза, то есть мы $V - 2$ раза взяли ребро не из разреза.
Она не меньше, чем
\[
    \left(1 - \frac{2}{V} \right) \left( 1 - \frac{2}{V - 1} \right) \dots \left(1 - \frac{2}{3} \right) =
\]
(приведём к общим знаменателям)
\[
    = \frac{V - 2}{V} \cdot \frac{V - 3}{V - 1} \cdot \frac{V - 4}{V - 2} \cdot \frac{V - 5}{V - 3} \cdots \frac{1}{3} = \frac{2}{V(V-1)} \ge \frac{2}{V^2}.
\]
Вероятность так себе, но давайте запустим алгоритм $C$ раз.
Так и не найдём ответ мы с вероятностью
\[
    \left(1 - \frac{2}{V^2} \right)^C \approx \frac{1}{e^k}
\]
при $C = \frac{V^2}{2} \cdot k$.

Это называется алгоритмом Каргера.

\subsubsection{Алгоритм Каргера-Штейна}
Положим $t = \frac{V}{\sqrt 2}$ и сожмём граф до $t$ вершин.
Аналогично предыдущим рассуждениям мы к этому моменту не сожмём ребро ответа с вероятностью хотя бы $\frac{1}{2}$.
Теперь запустим то же самое от полученного графа два раза.
Пусть $P(V)$ --- вероятность того, что мы не ошиблись на графе на $V$ вершинах.
Тогда
\[
    P(V) \ge \frac{1}{2} \left(1 - \left(1 - P \left( \frac{V}{\sqrt 2} \right) \right)^2 \right)
\]
--- чтобы не ошибиться мы должны не ошибиться при сжатии до $t$ вершин и не ошибиться хотя бы в одном из следующих запусков.
Пусть $V = (\sqrt 2)^k$.
Тогда $P(k) \ge \frac{1}{2} (1 - (1 - P(k - 1))^2)$.
Теперь утверждается, что $P(k) \ge \frac{1}{k}$.
Доказывается по индукции ($P(0) = 1$ и переход (может не работать при малых $k$)).
Время работы --- $O(V^2 \log(V))$ на итерацию.

\subsection{Минимальный остов за $O(E)$}
\textbf{Определение.} MSF --- Minimum Spanning Forest, подграф какого-то минимального остовного дерева.

\textbf{Определение.} Пусть $F$ --- какой-то минимальный остовный лес и ребро $e \in E$.
Тогда $e$ называется $F$-\textit{тяжёлым}, если $e \in F$ и $e$ --- максимальное ребро на стягиваемом им в $F$ цикле.
В противном случае оно называется $F$-\textit{лёгким}.

\textbf{Утверждение.} Если ребро $e$ $F$-тяжёлое относительно какого-то минимального остовного леса $F$, то $e$ не лежит ни в каком минимальном остовном лесе.

\textbf{Доказательство.} Рассмотрим произвольный остовный лес, содержащий $F$ тяжёлое ребро $(a, b)$.
Удалим ребро $(a, b)$.
Пройдём по вершинам из цикла $F$, стягиваемого $(a, b)$.
В какой-то момент мы пройдём по ребру из компоненты вершины $a$ в компоненту вершины $b$ нового графа --- добавим это ребро.

\subsubsection{Принцип работы}
Для начала запустим 3 шага алгоритма Борувки, чтобы размер графа уменьшался.
Возьмём $E' \subset E$ --- подмножество рёбер, где каждое ребро берётся с вероятностью $\frac{1}{2}$.
Пусть $G' = (V, E')$ --- новый граф, найдём на нём рекурсивно минимальный остовный лес $F'$.
Теперь найдём среди рёбер $E$ все $F'$-тяжёлые и положим их в $E''$.
Наконец, вернём минимальный остов на графе $(V, E \setminus E'')$.

\textbf{Замечание 1.} Рекурсивные запуски могли возвращать несвязные остовные леса, так как мы им могли дать несвязный граф, но результат будет связен.

\textbf{Замечание 2.} Множество $E''$ можно найти за $O(E)$, но это что-то сложное, и это не рассказали.

\subsubsection{Доказательство $O(E \log(V))$ в худшем случае}
\textbf{Утверждение.} $|E''| \ge |E'| - |V| + s$, где $s$ --- количество компонент связности в $G'$.
Следует из того, что в минимальном остовном дереве будет $|V| - s$ рёбер, и остальные будут тяжёлыми.

Тогда при рекурсивных запусках для графа $G = (V, E)$ у нас будет суммарно $|E'| + |E| - |E''| \le |E| + |V| - s$.
Но теперь вспомним, что мы ещё запускали Борувку, поэтому мы на самом деле работали не с $(V, E)$, а с $(V_3, E_3)$, где $|E_3| \le |E| - |V| + |V_3|$ (так как при каждом стягивании ребра мы удаляли одну вершину) и $|V_3| \le \frac{|V|}{8}$.
Тогда вернёмся к неравенству выше, заменяя $E$ на $E_3$ и $V$ на $V_3$:
\[
    |E'| + |E_3| - |E''| \le |E_3| + |V_3| - s \le |E| - |V| + |V_3| + |V_3| - s \le |E| - \frac{3|V|}{4}.
\]
Получаем, что суммарно в двух рекурсивных вызовах рёбер будет не больше, чем у нас сейчас, а глубина дерева --- $O(\log(V))$ засчёт Борувки.
Таким образом, в худшем случае это работает за $O(E \log(V))$.

\subsubsection{Доказательство $O(V + E)$ в среднем}
Пусть $T(G)$ --- время работы алгоритма на графе $G$.
Докажем по индукции, что
\[
    MT(G) \le A(V + E) + MT(G') + MT(V_3, E_3 \setminus E'').
\]
Здесь $M$ --- математическое ожидание, чтобы не было коллизии с $E$.
Что такое $MT(G')$? Это
\[
    \sum_{E'} P(E' \text{ появилось}) \cdot M'T(G') \le \sum_{E'} P(E' \text{ появилось}) \cdot C(|V_3| + |E'|) =
\]
Здесь $M'T(G')$ --- это математическое ожидание при фиксированном $E'$, а $MT(G')$ --- математическое ожидание по всем $E'$.
Это равно
\[
    = C|V_3| + C \sum_{E'} P(E' \text{ появилось}) |E'| = C|V_3| + CM|E'| = C \left(|V_3| + \frac{|E_3|}{2} \right).
\]

Теперь главная часть алгоритма. Мы знаем, что $F'$ --- это какой-то минимальный остовный лес, и его мог вернуть любой алгоритм, в частности, алгоритм Краскала (с СНМом).
Поэтому мы можем думать, что $F'$ был сгенерирован следующим алгоритмом: отсортируем рёбра и будем пробовать добавлять каждое с вероятностью $\frac{1}{2}$.
Пусть мы сейчас рассматриваем ребро $(u, v)$.
Если $u$ и $v$ лежат в одной компоненте $F'$, то оно точно $F'$-тяжёлое и попадёт в $E''$.
Если же в разных, то оно $F'$-лёгкое, и здесь уже имеет смысл бросать монетку.
Так как рёбер в $F'$ по итогу не более $|V_3| - 1$, монетка выпадет столько же раз, то есть математическое ожидание числа бросков монетки не превосходит $2|V_3|$. 
Это и есть математическое ожидание числа $F'$-лёгких рёбер, или же размера $|E \setminus E''|$.
Следовательно, $MT(V_3, E_3 \setminus E'') \le 3C |V_3|$.
Собирая всё вместе, получаем
\[
    MT(G) \le A(|V| + |E|) + C \left(|V_3| + \frac{|E_3|}{2} \right) + 3C|V_3| = 
\]
\[
    = A(|V| + |E|) + 4C|V_3| + C \frac{|E_3|}{2} \le A(|V| + |E|) + \frac{C|V|}{2} + C \frac{|E|}{2}.
\]
Это не превосходит $C(|V| + |E|)$ при $C \ge 2A$.

\textbf{Замечание.} Вообще, это проще доказывается через $T(n, m)$ --- время работы на графе с $n$ вершинами и $m$ рёбрами (тогда $MT(G) = C \left( |V_3| + \frac{|E_3|}{2} \right)$ будет следовать напрямую из предположения индукции), здесь же описан метод, использованный на лекции.

\subsection{Умножение булевых матриц}
Хотим для булевых матриц $A$ и $B$ размера $n \times n$ найти матрицу $C$, такую что $C_{i,j} = \bigvee_{k=1}^n (A_{i,k} \wedge V_{k,j})$.

\textbf{Определение.} $M(n) = O(n^{2.37})$ --- лучшее время, за которое человечество умеет детерминировано перемножать булевы матрицы размера $n \times n$.

\subsubsection{Наикратчайшие расстояния для всех пар вершин в графе}
Будем решать другую задачу: дана матрица смежности $A_{n \times n}$, найдём матрицу $D_{n \times n}$, где $D_{i,j} = \dist(i, j)$ в невзвешенном графе, задаваемом $A$.

\textbf{Замечание.} $A^k$ --- количество путей длины $k$ в графе.

Построим новый граф, в котором вершины $u$ и $v$ соединены тогда и только тогда, когда расстояние между ними в исходном графе не превосходит 2.
Иными словами, $A' = A^2 \vee A$.
Также определим для него матрицу $D'_{i,j}$ аналогично матрице $D$.

\textbf{Лемма 1.} $D'_{i,j} = \lceil \frac{D_{i,j}}{2} \rceil$.
Просто по построению.

\textbf{Лемма 2.} Если $D_{i,j}$ чётно, то для любого ребра $(i, v)$ верно $D'_{v,j} \ge D'_{i,j}$.
Если же нечётно, то найдётся вершина $v$ и ребро $(i, v)$, такие что $D'_{v,j} < D'_{i,j}$.
Более того, в этом случае для всех вершин $v$ и рёбер $(i, v)$ верно $D'_{v,j} \le D'_{i,j}$.

\textbf{Доказательство.} Так как граф невзвешен, $|D_{v,j} - D_{i,j}| \le 1$.
То есть если $D_{i,j} = 2x$, то $D_{v,j} \in \{2x - 1, 2x, 2x + 1\}$ и по лемме 1 $D'_{v,j} \ge x = D'_{i,j}$.
Остальные по этой же схеме.

\textbf{Следствие.} $D_{i,j}$ чётно тогда и только тогда, когда $\sum_{(i, v) \in E} D'_{v,j} \ge D'_{i,j} \cdot \deg(i)$.
(Просуммируем неравенства выше)

Это следствие позволяет нам восстановить чётность всех элементов матрицы $D$ по матрице $D'$ за одно матричное умножение, так как сумма слева --- не что иное, как элемент матрицы $A \cdot D'$.
А зная чётность $D_{i,j}$ и значение $D'_{i,j}$, мы можем однозначно восстановить $D_{i,j}$.
Но откуда мы возьмём $D'_{i,j}$? Всё просто: запустимся рекурсивно от $A'$ и $D'$.
В новом графе диаметр уменьшился в 2 раза, поэтому мы завершимся за $O(\log(n))$ шагов и получим итоговое время работы --- $O(M(n) \log(n))$.

\subsubsection{Нахождение свидетелей}
\textbf{Определение.} Свидетель булевого перемножения матриц --- индекс $k$, при котором $A_{i,k} \wedge B_{k,j} = 1$.

Сначала перемножим $A$ и $B$ и поймём, для каких элементов мы хотим искать свидетелей.
Положим матрицу $F$, такую что $F_{i,k} = A_{i,k} \cdot k$.
Тогда при умножении матрицы $F$ на $B$, если свидетель ровно один, мы его успешно и найдём.
Но если свидетелей несколько, то это не сработает.
Поэтому будем обнулять случайное множество столбцов, умножать и проверять, нашли ли мы свидетелей (это проверяется за $O(n^2)$).

Обнулим клетки из случайно выбранного множества $R$, такого что $|R| = r$.
Пусть у пары $(i, j)$ есть $w$ свидетелей.
Тогда вероятность того, что в новой матрице свидетель ровно один ---
\[
    \frac{w C_{n-w}^{r-1}}{C_n^r} = wr \frac{(n-w)! (n-r)!}{n! (n-w-r+1)!} = 
\]
\[
    = \frac{wr}{n} \cdot \frac{(n-r)(n-r-1) \dots (n-r-w+2)}{(n-1)(n-2) \dots (n-w+1)} =
\]
\[
    = \frac{wr}{n} \left(1 - \frac{r-1}{n-1} \right) \left(1 - \frac{r-1}{n-2} \right) \dots \left(1 - \frac{r-1}{n-w+1} \right) \ge
\]
\[
    \ge \frac{wr}{n} \left(1 - \frac{r-1}{n-w} \right)^{w-1} = \frac{wr}{n} \left( 1 - \frac{wr - w}{w(n - w)} \right)^{w - 1} \ge
\]
Предположим, что $\frac{wr}{n} \in \left[ \frac{1}{2}, 1 \right]$.
\[
    \ge \frac{wr}{n} \left( 1 - \frac{n - w}{w(n - w)} \right)^{w-1} \ge \frac{1}{2} \left(1 - \frac{1}{w} \right)^{w-1} \ge \frac{1}{2e}.
\]
Чтобы получить $\frac{wr}{n} \in \left[ \frac{1}{2}, 1 \right]$, будем брать $r = 1, 2, 4, 8, \dots$.
Теперь будем перезапускать алгоритм (для всех $r$) $k = \lceil \log_{1 - \frac{1}{2e}} \left( \frac{1}{n} \right) \rceil$ раз.
После этого могли остаться ненайденные свидетели, но их будет мало, и можно каждого находить отдельно за $O(n)$.
А сколько именно их будет?
Рассмотрим элемент $(i, j)$, пусть у него $w > 0$ свидетелей.
Посчитаем вероятность того, что ни один из свидетелей не нашёлся.

Существует $r$, такое что $\frac{wr}{n} \in \left[ \frac{1}{2}, 1 \right]$, и мы для этого $r$ пытались найти свидетеля $k$ раз.
Вероятность успеха каждой из этих итераций --- хотя бы $\frac{1}{2e}$, поэтому не нашли мы с вероятностью не более $\left(1 - \frac{1}{2e} \right)^k \le \frac{1}{n}$ по определению $k$.
Следовательно, математическое ожидание числа свидетелей не превосходит $n^2 \cdot \frac{1}{n} = n$.

Соответственно итоговое время работы --- $O(M(n) \log^2(n))$: логарифмы из-за $k$ и перебора $r$.

\subsubsection{Применение свидетелей к задаче о наикратчайших расстояниях}
Мы хотим научиться восстанавливать наикратчайшие пути между всеми парами вершин за $o(n^3)$.
В частности, мы хотим построить матрицу $S$, такую что $S_{i,j}$ --- первая вершина на одном из наикратчайших путей между $i$ и $j$, если начинать с вершины $i$.
Изучим свойства этой матрицы, пусть $v = S_{i,j}$.
Тогда $D_{i,v} = 1$ и $D_{i,j} = D_{v,j} + 1$.
В частности, $D_{v,j} \equiv D_{i,j} - 1 \mod 3$.
При чём тут модуль 3?
Вспомним, что граф у нас неориентированный и невзвешенный, поэтому для любой инцидентной $i$ вершине $u$ выполнено $D_{u,j} \in \{D_{i,j} - 1, D_{i,j}, D_{i,j} + 1\}$ --- сравнимость по модулю будет верна только для одной из подходящих вершин $v$.
Определим три булевы матрицы $G^k$, у которых элемент $(i, j)$ равен единице в случае, когда $D_{i,j} \equiv k \mod 3$.
Тогда $S_{i,j}$ --- это в точности свидетель умножения булевых матриц $A$ и $B = (G_{i,j}^{D_{i,j} - 1 \mod 3})$.
Время работы --- сумма времён работы нахождения $D$ и умножения со свидетелями, то есть $O(M(n) \log^2(n))$ в среднем.
